{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_CalculatingMissingValues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_aajCM3T6-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "d253d875-89fb-44c5-cfc2-bb3b205f5797"
      },
      "source": [
        "!pip install wfdb\n",
        "import io\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import posixpath\n",
        "import wfdb\n",
        "import urllib.request\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/ee/6844bc943a28fea501773c033b0da5f6cfc9509a014d0ba1e29e44b763ee/wfdb-3.0.1-py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.15.1)\n",
            "Collecting mne>=0.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/ab/9b79f927b599da515335afb4b666a7bb336930a6d8345e7b483a9980a9c1/mne-0.20.7-py3-none-any.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2018.9)\n",
            "Requirement already satisfied: six>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.4.7)\n",
            "Requirement already satisfied: chardet>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.0.4)\n",
            "Requirement already satisfied: urllib3>=1.22 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.18.5)\n",
            "Collecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.4.1)\n",
            "Collecting threadpoolctl>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.0.5)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.22.2.post1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.9)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.10.0)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2016.8.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2020.4.5.2)\n",
            "Installing collected packages: mne, nose, threadpoolctl, wfdb\n",
            "Successfully installed mne-0.20.7 nose-1.3.7 threadpoolctl-2.1.0 wfdb-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYf1-Ek60U8q",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d3e3d067-7435-4184-9c3a-9fb395c1f4bb"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c37a9ae-75df-423c-ab22-2f2bb9fddf9b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c37a9ae-75df-423c-ab22-2f2bb9fddf9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_TS_exists_withoutTEMP_overlapcount.csv to df_TS_exists_withoutTEMP_overlapcount.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUt-SWiO0YWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cc5a146-b4e2-4161-da8c-4af51613c4d5"
      },
      "source": [
        "df_csvdata = pd.read_csv(io.BytesIO(uploaded['df_TS_exists_withoutTEMP_overlapcount.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "print ('shape of original dataframe from CSV : ', df_csvdata.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of original dataframe from CSV :  (4653, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKuFI0KQ0lXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4df9d07-55c6-4748-a3bd-51993822dadf"
      },
      "source": [
        "df_csvdata = df_csvdata[(df_csvdata['sig_exists'] == 1) & (df_csvdata['timeoverlap'] == 1)]\n",
        "df_csvdata['first24']=''; \n",
        "df_csvdata['first12']='';\n",
        "df_csvdata['first6']='';\n",
        "df_csvdata['6around_onset']='';\n",
        "df_csvdata['8around_onset']='';\n",
        "df_csvdata['entire_stay']='';\n",
        "df_csvdata['gap']='';\n",
        "print ('Shape of dataframe with only ICU stays for whom the signals and time overlap exists : ',df_csvdata.shape )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of dataframe with only ICU stays for whom the signals and time overlap exists :  (1655, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrVqPOxL0QB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "from urllib.request import urlopen\n",
        "\n",
        "df_ts_records_columns = ['RECORD','TIME','HR', 'SPO2','ABPSYS','ABPDIAS','ABPMEAN','RESP'] \n",
        "\n",
        "for index, row in df_csvdata.iterrows():\n",
        "    print(row['subject_id']);\n",
        "    try:\n",
        "      df_ts_records.drop(df_ts_records.index,inplace=True)\n",
        "    except:\n",
        "      print('MAIN DF does not exits')\n",
        "\n",
        "    df_ts_records = pd.DataFrame(columns=df_ts_records_columns);\n",
        "\n",
        "    wdb_dir_path = 'mimic3wdb/matched/p'+ str(row['subject_id']).zfill(6)[:2] + '/p' + str(row['subject_id']).zfill(6) + '/';\n",
        "    wdb_path_toAllRecords = 'https://archive.physionet.org/physiobank/database/'+ wdb_dir_path + 'RECORDS';\n",
        "    #print(wdb_path_toAllRecords)\n",
        "    wdb_records =  urllib.request.urlopen(wdb_path_toAllRecords);   \n",
        "    #print('SUCCESS')\n",
        "    count_overlap = 0;\n",
        "    gap = ''; \n",
        "    for lines in wdb_records.readlines():\n",
        "      record = lines.decode(\"utf-8\"); \n",
        "      record = str(record).rstrip()\n",
        "      #print (record[-1:])\n",
        "      if record[-1:] == 'n':\n",
        "        #print(record);\n",
        "        #print (wdb_dir_path);\n",
        "        consider_record =0 ;\n",
        "        record = str(record).rstrip()\n",
        "\n",
        "        try:\n",
        "          signals =''\n",
        "          fields = ''\n",
        "          #print(record)\n",
        "          #print(wdb_dir_path)\n",
        "          signals,fields = wfdb.rdsamp(record, pn_dir=wdb_dir_path) ; \n",
        "          list_sig_name = [item.upper().replace(' ','') for item in fields['sig_name']]\n",
        "          sig_exist_1 = all(x in list_sig_name for x in ['HR', 'SPO2','ABPSYS','ABPDIAS','ABPMEAN','RESP']);  #%SpO2\n",
        "          sig_exist_2 = all(x in list_sig_name for x in ['HR', '%SPO2','ABPSYS','ABPDIAS','ABPMEAN','RESP']); \n",
        "          if ((sig_exist_1 == True) or (sig_exist_2 == True)) :\n",
        "            consider_record = 1\n",
        "          else:\n",
        "            consider_record = 0\n",
        "          record_starttime = datetime.datetime.combine(fields['base_date'] ,fields['base_time'] ) ;\n",
        "          if  '%.3f'%(fields['fs']) == '1.000' :\n",
        "            record_endtime = record_starttime + datetime.timedelta(seconds= (fields['sig_len']-1)) ;\n",
        "          elif '%.3f'%(fields['fs'])== '0.017' :\n",
        "            record_endtime = record_starttime + datetime.timedelta(minutes = (fields['sig_len']-1)) ;\n",
        "          else : \n",
        "            print('ERROR IN SAMPLING');\n",
        "            print(record);\n",
        "            print (wdb_dir_path);\n",
        "          #Caculate if we have a recording for the time of icu stay\n",
        "          Range = namedtuple('Range', ['start', 'end'])\n",
        "          r1 = Range(start= datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S'), end= datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S'))\n",
        "          r2 = Range(start= record_starttime, end = record_endtime)\n",
        "          latest_start = max(r1.start, r2.start)\n",
        "          earliest_end = min(r1.end, r2.end)\n",
        "          delta = (earliest_end - latest_start).days + 1\n",
        "          df_row_idx = df_ts_records.shape[0] ;\n",
        "          if ((delta >= 0 ) & (consider_record ==1)) :\n",
        "            #print('RECORD EXISTS FOR THE ICU STAYS WITH THE SIGNALS NEEDED : ', row['subject_id'])\n",
        "            #df_csvdata.loc[index,'timeoverlap'] = 1;\n",
        "            #todo : adding new dataframe, exatracting required signals, computing avergage for per sminute values in case of per second sampling frequency\n",
        "            for i in fields['sig_name']:\n",
        "              if i.upper().replace(' ','') == 'HR':\n",
        "                idx_HR='';\n",
        "                idx_HR = fields['sig_name'].index(i);\n",
        "              elif (( i.upper().replace(' ','') == 'SPO2') or (i.upper().replace(' ','') =='%SPO2')):\n",
        "                idx_SPO2 = '';\n",
        "                idx_SPO2 = fields['sig_name'].index(i);\n",
        "              elif i.upper().replace(' ','') == 'ABPSYS' :\n",
        "                idx_ABPSYS = '';\n",
        "                idx_ABPSYS = fields['sig_name'].index(i);\n",
        "              elif i.upper().replace(' ','') == 'ABPDIAS' :\n",
        "                idx_ABPDIAS = '';\n",
        "                idx_ABPDIAS = fields['sig_name'].index(i);\n",
        "              elif i.upper().replace(' ','') == 'ABPMEAN' :\n",
        "                idx_ABPMEAN = '';\n",
        "                idx_ABPMEAN = fields['sig_name'].index(i);\n",
        "              elif i.upper().replace(' ','') == 'RESP' :\n",
        "                idx_RESP = '';\n",
        "                idx_RESP = fields['sig_name'].index(i);\n",
        "                \n",
        "            if count_overlap == 0 : \n",
        "              if record_starttime > (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ):\n",
        "                #print('inserting nulls between icu intime and record start time')\n",
        "                minutes_to_insert_start = record_starttime - (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') )\n",
        "                #print('minutes_to_insert_start:  ', minutes_to_insert_start)\n",
        "                duration_in_s = minutes_to_insert_start.total_seconds()\n",
        "                minutes_to_insert_start = divmod(duration_in_s, 60)[0] - 1 \n",
        "                gap = gap + ',' + str(minutes_to_insert_start)\n",
        "                try:\n",
        "                  df_ts_records_time_temp_start.drop(df_ts_records_time_temp_start.index,  inplace=True)\n",
        "                except :\n",
        "                  print( 'df_ts_records_time_temp_start does not exist')\n",
        "                df_ts_records_time_temp_start = pd.DataFrame(columns=df_ts_records_columns)\n",
        "                if '%.3f'%(fields['fs'])== '0.017' :\n",
        "                  df_ts_records_time_temp_start['TIME'] = pd.date_range((datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(minutes=1), \n",
        "                                                              periods = minutes_to_insert_start, freq='1min'); \n",
        "                elif '%.3f'%(fields['fs'])== '1.000' :\n",
        "                  df_ts_records_time_temp_start['TIME'] = pd.date_range((datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(seconds=1), \n",
        "                                                              periods = (duration_in_s-1), freq='S');  \n",
        "                df_ts_records = df_ts_records.append(df_ts_records_time_temp_start, ignore_index=True);\n",
        "                gap = gap + ',start:' + str(minutes_to_insert_start)\n",
        "\n",
        "              try:\n",
        "                df_ts_records_temp.drop(df_ts_records_temp.index,  inplace=True)\n",
        "              except:\n",
        "                print( 'df_ts_records_time_temp_start does not exist')\n",
        "              df_ts_records_temp = pd.DataFrame(columns=df_ts_records_columns)\n",
        "              df_ts_records_temp['HR']= signals[:,idx_HR ] \n",
        "              df_ts_records_temp['SPO2']= signals[:,idx_SPO2 ] \n",
        "              df_ts_records_temp['ABPSYS']= signals[:,idx_ABPSYS ] \n",
        "              df_ts_records_temp['ABPDIAS']= signals[:,idx_ABPDIAS ] \n",
        "              df_ts_records_temp['ABPMEAN']= signals[:,idx_ABPMEAN ] \n",
        "              df_ts_records_temp['RESP']= signals[:,idx_RESP ] \n",
        "              if '%.3f'%(fields['fs'])== '0.017' :\n",
        "                df_ts_records_temp['TIME'] = pd.date_range(record_starttime, periods=fields['sig_len'], freq='1min'); \n",
        "              elif '%.3f'%(fields['fs'])== '1.000' :\n",
        "                df_ts_records_temp['TIME'] = pd.date_range(record_starttime, periods=fields['sig_len'], freq='S'); \n",
        "              df_ts_records_temp.TIME = pd.to_datetime(df_ts_records_temp.TIME)\n",
        "              df_ts_records = df_ts_records.append(df_ts_records_temp, ignore_index=True);\n",
        "\n",
        "\n",
        "            else:\n",
        "              if record_starttime < (datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S') ) :\n",
        "                last_Record_time = df_ts_records.loc[(df_row_idx-1),'TIME']\n",
        "                #print('main DF last time record: ',last_Record_time )\n",
        "                minutes_to_insert = record_starttime - last_Record_time\n",
        "                duration_in_s = minutes_to_insert.total_seconds()\n",
        "                minutes_to_insert = divmod(duration_in_s, 60)[0] - 1\n",
        "                #print ('minutes_to_insert:  ', minutes_to_insert);\n",
        "                try:\n",
        "                  df_ts_records_time_temp.drop(df_ts_records_time_temp.index, inplace= True);\n",
        "                  df_ts_records_temp.drop(df_ts_records_temp.index, inplace=True);\n",
        "                except:\n",
        "                  print ('df_ts_records_temp and df_ts_records_time_temp does not exits')\n",
        "                df_ts_records_time_temp = pd.DataFrame(columns=df_ts_records_columns)\n",
        "                if '%.3f'%(fields['fs'])== '0.017' :\n",
        "                  df_ts_records_time_temp['TIME'] = pd.date_range(last_Record_time + datetime.timedelta(minutes=1), \n",
        "                                                              periods=minutes_to_insert, freq='1min'); \n",
        "                elif '%.3f'%(fields['fs'])== '1.000' :\n",
        "                  df_ts_records_time_temp['TIME'] = pd.date_range(last_Record_time + datetime.timedelta(seconds=1), \n",
        "                                                              periods=(duration_in_s-1), freq='S'); \n",
        "                #print ('df_ts_records_time_temp:')\n",
        "                #print (df_ts_records_time_temp)\n",
        "                df_ts_records = df_ts_records.append(df_ts_records_time_temp, ignore_index=True);\n",
        "                gap = gap + ',mid:' + str(minutes_to_insert)\n",
        "              \n",
        "                df_ts_records_temp = pd.DataFrame(columns=df_ts_records_columns)\n",
        "                df_ts_records_temp['HR']= signals[:,idx_HR ] \n",
        "                df_ts_records_temp['SPO2']= signals[:,idx_SPO2 ] \n",
        "                df_ts_records_temp['ABPSYS']= signals[:,idx_ABPSYS ] \n",
        "                df_ts_records_temp['ABPDIAS']= signals[:,idx_ABPDIAS ] \n",
        "                df_ts_records_temp['ABPMEAN']= signals[:,idx_ABPMEAN ] \n",
        "                df_ts_records_temp['RESP']= signals[:,idx_RESP ] \n",
        "                if '%.3f'%(fields['fs'])== '0.017' :\n",
        "                  df_ts_records_temp['TIME'] = pd.date_range(record_starttime, periods=fields['sig_len'], freq='1min'); \n",
        "                elif  '%.3f'%(fields['fs'])== '1.000' :\n",
        "                  df_ts_records_temp['TIME'] = pd.date_range(record_starttime, periods=fields['sig_len'], freq='S'); \n",
        "                df_ts_records_temp.TIME = pd.to_datetime(df_ts_records_temp.TIME)\n",
        "                df_ts_records = df_ts_records.append(df_ts_records_temp, ignore_index=True);\n",
        "\n",
        "        \n",
        "            df_ts_records['RECORD'] = record\n",
        "\n",
        "            \"\"\"\n",
        "            if '%.3f'%(fields['fs'])== '1.000' :\n",
        "              start_idx = 0;\n",
        "              df_ts_records_new = pd.DataFrame(columns=df_ts_records_columns);\n",
        "              #print('length of new df  '  , df_ts_records_new.shape[0] )\n",
        "              for index, rows in df_ts_records.iterrows():\n",
        "                if start_idx >= df_ts_records.shape[0]:\n",
        "                  exit;\n",
        "                else: \n",
        "                  #print(df_ts_records.iloc[start_idx: (start_idx+60), 2:8])\n",
        "                  array = np.array( df_ts_records.iloc[start_idx: (start_idx+60), 2:8].mean(axis=0))\n",
        "                  #print('printing array of average')\n",
        "                  #print (array)\n",
        "\n",
        "                  current_index = df_ts_records_new.shape[0]\n",
        "                  df_ts_records_new.loc[current_index ,'HR']= array[0]\n",
        "                  df_ts_records_new.loc[current_index,'SPO2']= array[1]\n",
        "                  df_ts_records_new.loc[current_index,'ABPSYS']= array[2]\n",
        "                  df_ts_records_new.loc[current_index,'ABPDIAS']= array[3]\n",
        "                  df_ts_records_new.loc[current_index,'ABPMEAN']= array[4]\n",
        "                  df_ts_records_new.loc[current_index,'RESP']= array[5]\n",
        "\n",
        "                  #print(df_ts_records_new)\n",
        "                  #print('next average')\n",
        "                  start_idx = start_idx+60;\n",
        "                  #print('start index :: ' , start_idx)\n",
        "\n",
        "              df_ts_records_new['TIME'] = pd.date_range(df_ts_records.loc[0,'TIME'], periods= df_ts_records_new.shape[0], freq='1min'); \n",
        "              df_ts_records_new.TIME = pd.to_datetime(df_ts_records_new.TIME)\n",
        "              #print(df_ts_records_new)\n",
        "              df_ts_records.drop(df_ts_records.index, inplace=True);\n",
        "              df_ts_records = pd.DataFrame(columns=df_ts_records_columns)\n",
        "              df_ts_records = df_ts_records.append(df_ts_records_new, ignore_index=True);\n",
        "            \"\"\"\n",
        "            #print('Appended dataframe')\n",
        "            #print(df_ts_records)\n",
        "            FS = '%.3f'%(fields['fs'])\n",
        "            count_overlap = count_overlap +1\n",
        "\n",
        "\n",
        "          else:            \n",
        "            print('RECORD DOES NOT EXISTS FOR THE ICU STAYS WITH THE SIGNALS NEEDED : ', row['subject_id'])\n",
        "              #df_csvdata.loc[index,'timeoverlap'] = 0;\n",
        "\n",
        "        except ValueError:\n",
        "          print('Error occured while reading waveform: ', record);\n",
        "\n",
        "\n",
        "    #print((datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=24))\n",
        "    try:\n",
        "      last_record_idx = df_ts_records.shape[0] - 1\n",
        "      all_records_end_time = df_ts_records.loc[last_record_idx,'TIME']\n",
        "      if (all_records_end_time < (datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S') ) ):\n",
        "        print('INSERTING NULLS AT THE END')\n",
        "        try:\n",
        "          df_ts_records_time_temp_end.drop(df_ts_records_time_temp_end.index, inplace=True)\n",
        "        except:\n",
        "          print('df_ts_records_time_temp_end does not exists')\n",
        "        #print('main DF last time record: ',last_Record_time )\n",
        "        minutes_to_insert_end = (datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S') ) - all_records_end_time\n",
        "        duration_in_s = minutes_to_insert_end.total_seconds()\n",
        "        minutes_to_insert_end = divmod(duration_in_s, 60)[0] - 1\n",
        "\n",
        "        df_ts_records_time_temp_end = pd.DataFrame(columns=df_ts_records_columns)\n",
        "        if FS == '0.017' :\n",
        "          df_ts_records_time_temp_end['TIME'] = pd.date_range(all_records_end_time + datetime.timedelta(minutes=1), \n",
        "                                                              periods=minutes_to_insert_end, freq='1min'); \n",
        "        elif FS == '1.000' :\n",
        "          df_ts_records_time_temp_end['TIME'] = pd.date_range(all_records_end_time + datetime.timedelta(seconds=1), \n",
        "                                                              periods=(duration_in_s-1), freq='S'); \n",
        "        df_ts_records = df_ts_records.append(df_ts_records_time_temp_end, ignore_index=True);\n",
        "        gap = gap + ',end:' + str(minutes_to_insert_end)\n",
        "\n",
        "      \n",
        "      df_csvdata.loc[index,'gap'] = gap;\n",
        "      total_rows_first24hour = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=24) )].shape[0]\n",
        "      total_rows_first24hour_notNAN = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=24) )].dropna().shape[0]\n",
        "      percent_notNANdata_24 = round(total_rows_first24hour_notNAN / total_rows_first24hour , 2) * 100 \n",
        "      if percent_notNANdata_24 >= 80:\n",
        "        print('selected record for first 24 : ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'first24'] = 1;\n",
        "      else:\n",
        "        print('not selected for first 24: ', row['subject_id'])\n",
        "\n",
        "      total_rows_first12hour = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=12) )].shape[0]\n",
        "      total_rows_first12hour_notNAN = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=12) )].dropna().shape[0]\n",
        "      percent_notNANdata_12 = round(total_rows_first12hour_notNAN / total_rows_first12hour , 2) * 100\n",
        "      if percent_notNANdata_12 >= 80:\n",
        "        print('selected record for first 12: ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'first12'] = 1;\n",
        "      else:\n",
        "        print('not selected for first 12: ', row['subject_id'])\n",
        "\n",
        "      total_rows_first6hour = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=6) )].shape[0]\n",
        "      total_rows_first6hour_notNAN = df_ts_records[(df_ts_records['TIME'] <= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=6) )].dropna().shape[0]\n",
        "      percent_notNANdata_6 = round(total_rows_first6hour_notNAN / total_rows_first6hour , 2) * 100 \n",
        "      if percent_notNANdata_6 >= 80:\n",
        "        print('selected record for first 6 : ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'first6'] = 1;\n",
        "      else:\n",
        "        print('not selected for first 6: ', row['subject_id'])\n",
        "      \n",
        "      total_rows_entire_stay = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') )  )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S') )  )].shape[0]\n",
        "      total_rows_entire_stay_notNAN = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['intime'],'%Y-%m-%d %H:%M:%S') )  )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['outtime'],'%Y-%m-%d %H:%M:%S') )  )].dropna().shape[0]\n",
        "      percent_notNANdata_entire_stay = round(total_rows_entire_stay_notNAN / total_rows_entire_stay , 2) * 100 \n",
        "      if percent_notNANdata_entire_stay >= 80:\n",
        "        print('selected record for entire icu stay : ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'entire_stay'] = 1;\n",
        "      else:\n",
        "        print('not selected for entire icu stay : ', row['subject_id'])\n",
        "\n",
        "      \n",
        "      total_rows_6around_onset = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) - datetime.timedelta(hours=6) )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=6) )].shape[0]\n",
        "      total_rows_6around_onset_notNAN = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) - datetime.timedelta(hours=6) )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=6) )].dropna().shape[0]\n",
        "      percent_notNANdata_6around_onset = round(total_rows_6around_onset_notNAN / total_rows_6around_onset , 2) * 100 \n",
        "      if percent_notNANdata_6around_onset >= 80:\n",
        "        print('selected record for 6 around sepsis onsettime : ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'6around_onset'] = 1;\n",
        "      else:\n",
        "        print('not selected for 6 around sepsis onsettime : ', row['subject_id'])\n",
        "\n",
        "      \n",
        "      total_rows_8around_onset = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) - datetime.timedelta(hours=8) )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=8) )].shape[0]\n",
        "      total_rows_8around_onset_notNAN = df_ts_records[(df_ts_records['TIME'] >= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) - datetime.timedelta(hours=8) )\n",
        "                                & (df_ts_records['TIME'] <= (datetime.datetime.strptime(row['sepsis_onsettime'],'%Y-%m-%d %H:%M:%S') ) + datetime.timedelta(hours=8) )].dropna().shape[0]\n",
        "      percent_notNANdata_8around_onset = round(total_rows_8around_onset_notNAN / total_rows_8around_onset , 2) * 100 \n",
        "      if percent_notNANdata_8around_onset >= 80:\n",
        "        print('selected record for 8 around sepsis onsettime : ', row['subject_id'])\n",
        "        df_csvdata.loc[index,'8around_onset'] = 1;\n",
        "      else:\n",
        "        print('not selected for 8 around sepsis onsettime : ', row['subject_id'])\n",
        "\n",
        "      \n",
        "\n",
        "    except:\n",
        "      print('Error occured while reading waveform for patient: ', row['subject_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i95vRiQy0muj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e809db6e-41bd-499a-fcbb-b4133cc45183"
      },
      "source": [
        "\n",
        "print('count for entire icu: ', df_csvdata[(df_csvdata['entire_stay'] == 1)  ].shape[0]);\n",
        "print('count for first 24: ', df_csvdata[(df_csvdata['first24'] == 1) ].shape[0]);\n",
        "print('count for first 12: ', df_csvdata[(df_csvdata['first12'] == 1) ].shape[0]);\n",
        "print('count for first 6: ', df_csvdata[( df_csvdata['first6'] == 1) ].shape[0]);\n",
        "print('count for 6 around onset: ', df_csvdata[(df_csvdata['6around_onset'] == 1) ].shape[0]);\n",
        "print('count for 8 around onset: ', df_csvdata[(df_csvdata['8around_onset'] == 1) ].shape[0]);\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count for entire icu:  239\n",
            "count for first 24:  404\n",
            "count for first 12:  343\n",
            "count for first 6:  262\n",
            "count for 6 around onset:  120\n",
            "count for 8 around onset:  144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddr_N5UNRnFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_csvdata.to_csv ('df_TS_exists_withoutTEMP_MissingValues.csv', sep=',', index = False, header=True);\n",
        "\n",
        "from google.colab import files\n",
        "files.download('df_TS_exists_withoutTEMP_MissingValues.csv')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FolaGzQUNOB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}