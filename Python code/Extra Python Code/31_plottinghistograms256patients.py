# -*- coding: utf-8 -*-
"""31_plottingHistograms256Patients.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mouP3rSVmBbfwLptCz2E7o3CdlvIlDvp
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import pandas as pd
import io
import pandas as pd
from IPython.display import display
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import os
import shutil
import posixpath
import urllib.request
import datetime
from collections import namedtuple

from google.colab import files
uploaded = files.upload()

df_icutime = pd.read_csv(io.BytesIO(uploaded['Only_AllSepsisPatients_with_MissingData_FromSepsisOnset_ToShockOnset_or_SepsisOnset+31h.csv']))
print (df_icutime.columns)
#df_icutime = df_icutime[['subject_id','icustay_id','intime','outtime','sepsis_onsettime']]
#print (df_icutime.columns)
"""
df_icutime['intime'] =  pd.to_datetime(df_icutime['intime'])
df_icutime['outtime'] =  pd.to_datetime(df_icutime['outtime'])
"""

df_sepsisOnset_SepsisOnsetPlus31h_csvdata = df_icutime[(df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_timeoverlap_exists']==1)& (df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_percentNonMissingData']>=80) ]
print(df_sepsisOnset_SepsisOnsetPlus31h_csvdata.shape[0])

df_shock = df_sepsisOnset_SepsisOnsetPlus31h_csvdata[df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'].notna()]
print(df_shock.shape[0])
print(df_shock.columns )

df_shock['sepsis_onsettime'] =  pd.to_datetime(df_shock['sepsis_onsettime'])
df_shock['sepstic_shock_onsettime'] =  pd.to_datetime(df_shock['sepstic_shock_onsettime'])

df_shock['shock_minus_sepsis_time'] = (df_shock.sepstic_shock_onsettime-df_shock.sepsis_onsettime).astype('timedelta64[h]')

print(df_shock[['icustay_id','sepstic_shock_onsettime', 'sepsis_onsettime','shock_minus_sepsis_time']])

print(np.asarray(df_shock['shock_minus_sepsis_time']))

df_shock['shock_minus_sepsis_time'].hist(bins=256)
#df_shock['shock_minus_sepsis_time'].groupby('shock_minus_sepsis_time').count().plot.bar()

df_bar_chart = df_shock[['icustay_id','shock_minus_sepsis_time']]
df_bar_chart.groupby('shock_minus_sepsis_time').count().plot.bar()

print(df_shock[df_shock['shock_minus_sepsis_time']<= 9].shape[0])
print(df_shock[(df_shock['shock_minus_sepsis_time'] > 9 ) & (df_shock['shock_minus_sepsis_time']<= 24)].shape[0])
print(df_shock[(df_shock['shock_minus_sepsis_time'] > 24 ) & (df_shock['shock_minus_sepsis_time']<= 68)].shape[0])
print(df_shock[df_shock['shock_minus_sepsis_time']> 68].shape[0])

"""# **Perform experiments on these subgroups**"""

drive.mount('/content/gdrive')

# Download All Time series data for 404 patients.
df_all256_withTemp = pd.read_csv('/content/gdrive/My Drive/Master thesis/df_ts_records_all256SepsisPatients(lessThan20%Missing)_fromSepsisOnset_ShockOnset_or_sepsisOnsetPlus31h_WITH_TEMP_SOFA.csv')
df_all256_withTemp['TIME'] =  pd.to_datetime(df_all256_withTemp['TIME'])
print(df_all256_withTemp.shape)

#cleaning data :  removing all negative values

df_all256_withTemp.HR = df_all256_withTemp.HR.mask(df_all256_withTemp.HR < 0)

df_all256_withTemp.RESP = df_all256_withTemp.RESP.mask(df_all256_withTemp.RESP < 0)

df_all256_withTemp.ABPSYS = df_all256_withTemp.ABPSYS.mask(df_all256_withTemp.ABPSYS < 0)

df_all256_withTemp.ABPDIAS = df_all256_withTemp.ABPDIAS.mask(df_all256_withTemp.ABPDIAS < 0)

df_all256_withTemp.ABPMEAN = df_all256_withTemp.ABPMEAN.mask(df_all256_withTemp.ABPMEAN < 0)

df_all256_withTemp.SPO2 = df_all256_withTemp.SPO2.mask(df_all256_withTemp.SPO2 < 0)

df_all256_withTemp.TEMP = df_all256_withTemp.TEMP.mask(df_all256_withTemp.TEMP < 0)


df_all256_withTemp.SOFA_SCORE = df_all256_withTemp.SOFA_SCORE.mask(df_all256_withTemp.SOFA_SCORE < 0)


df_all256_withTemp.RESP_SOFA = df_all256_withTemp.RESP_SOFA.mask(df_all256_withTemp.RESP_SOFA < 0)


df_all256_withTemp.LIVER_SOFA = df_all256_withTemp.LIVER_SOFA.mask(df_all256_withTemp.LIVER_SOFA < 0)


df_all256_withTemp.RENAL_SOFA = df_all256_withTemp.RENAL_SOFA.mask(df_all256_withTemp.RENAL_SOFA < 0)


df_all256_withTemp.CARDIO_SOFA = df_all256_withTemp.CARDIO_SOFA.mask(df_all256_withTemp.CARDIO_SOFA < 0)


df_all256_withTemp.CNS_SOFA = df_all256_withTemp.CNS_SOFA.mask(df_all256_withTemp.CNS_SOFA < 0)


df_all256_withTemp.COAG_SOFA = df_all256_withTemp.COAG_SOFA.mask(df_all256_withTemp.COAG_SOFA < 0)

# Missing value imputation by carry forward scheme
df_all256_withTemp_cleaned_MVimputed = df_all256_withTemp.ffill().bfill()

df_all256_withTemp_cleaned_MVimputed.HR = df_all256_withTemp_cleaned_MVimputed.HR.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.RESP = df_all256_withTemp_cleaned_MVimputed.RESP.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPSYS = df_all256_withTemp_cleaned_MVimputed.ABPSYS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPDIAS = df_all256_withTemp_cleaned_MVimputed.ABPDIAS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPMEAN = df_all256_withTemp_cleaned_MVimputed.ABPMEAN.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.SPO2 = df_all256_withTemp_cleaned_MVimputed.SPO2.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.TEMP = df_all256_withTemp_cleaned_MVimputed.TEMP.round(decimals=4)


df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE = df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA = df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA = df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.COAG_SOFA = df_all256_withTemp_cleaned_MVimputed.COAG_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA = df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CNS_SOFA = df_all256_withTemp_cleaned_MVimputed.CNS_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RESP_SOFA = df_all256_withTemp_cleaned_MVimputed.RESP_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed['TIME'] =  pd.to_datetime(df_all256_withTemp_cleaned_MVimputed['TIME'])

# Check if any null values exists in the final dataframe after cleaning and imputing missing values.
print(df_all256_withTemp_cleaned_MVimputed[df_all256_withTemp_cleaned_MVimputed.isnull().any(axis=1)])

subject_ids = df_all256_withTemp_cleaned_MVimputed.SUBJECT_ID.unique()
#print((subject_ids))

from google.colab import files
uploaded = files.upload()

"""
df_icutime = pd.read_csv(io.BytesIO(uploaded['Only_AllSepsisPatients_with_MissingData_FromSepsisOnset_ToShockOnset_or_SepsisOnset+31h.csv']))
print (df_icutime.columns)



# extracting only patients with time overlap and less than 20 % missing data

df_sepsisOnset_SepsisOnsetPlus31h_csvdata = df_icutime[(df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_timeoverlap_exists']==1)& (df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_percentNonMissingData']>=80) ]
print(df_sepsisOnset_SepsisOnsetPlus31h_csvdata.shape[0])


df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepsis_onsettime'] =  pd.to_datetime(df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepsis_onsettime'])
df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'] =  pd.to_datetime(df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'])
# extracting only patients with time overlap and less than 20 % missing data and SHOCK group

df_shock_grp = df_sepsisOnset_SepsisOnsetPlus31h_csvdata[df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'].notna()]

df_shock_grp['shock_minus_sepsis_time'] = (df_shock_grp.sepstic_shock_onsettime-df_shock_grp.sepsis_onsettime).astype('timedelta64[h]')
df_shock_grp_9h = df_shock_grp[df_shock_grp['shock_minus_sepsis_time']<= 9]

subject_ids = df_shock_grp_9h.subject_id.unique()
print(len(subject_ids))

# extracting only patients with time overlap and less than 20 % missing data and NON - SHOCK group
df_nonshock_grp = df_sepsisOnset_SepsisOnsetPlus31h_csvdata[df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'].isna()]
df_nonshock_grp = df_nonshock_grp.iloc[:46,:]
nonShock_subject_ids = df_nonshock_grp.subject_id.unique()
print(len(nonShock_subject_ids))


subject_ids = np.asarray(subject_ids)
nonShock_subject_ids = np.asarray(nonShock_subject_ids)
# merging both shock and non shock grp patients
subject_ids = np.concatenate((subject_ids, nonShock_subject_ids))

print(len(subject_ids))

"""

"""
feature_cols= ['SUBJECT_ID','SEPSIS_ONSETTIME','SEPSIS_SHOCK_ONSETTIME','HAS_SHOCK',
               'HR_MIN','HR_MAX','HR_MEAN','HR_STD','HR_VAR',
               'RESP_MIN','RESP_MAX','RESP_MEAN','RESP_STD','RESP_VAR',
               'ABPSYS_MIN','ABPSYS_MAX','ABPSYS_MEAN','ABPSYS_STD','ABPSYS_VAR',
               'ABPDIAS_MIN','ABPDIAS_MAX','ABPDIAS_MEAN','ABPDIAS_STD','ABPDIAS_VAR',
               'ABPMEAN_MIN','ABPMEAN_MAX','ABPMEAN_MEAN','ABPMEAN_STD','ABPMEAN_VAR',
               'SPO2_MIN','SPO2_MAX','SPO2_MEAN','SPO2_STD','SPO2_VAR',
               'TEMP_MIN','TEMP_MAX','TEMP_MEAN','TEMP_STD','TEMP_VAR' ] 
"""
feature_cols= ['SUBJECT_ID','SEPSIS_ONSETTIME','SEPSIS_SHOCK_ONSETTIME','HAS_SHOCK',
               'HR_MEAN_1',
               'RESP_MEAN_1',
               'ABPSYS_MEAN_1',
               'ABPDIAS_MEAN_1',
               'ABPMEAN_MEAN_1',
               'SPO2_MEAN_1',
               'TEMP_MEAN_1' ,
               'HR_MEAN_2',
               'RESP_MEAN_2',
               'ABPSYS_MEAN_2',
               'ABPDIAS_MEAN_2',
               'ABPMEAN_MEAN_2',
               'SPO2_MEAN_2',
               'TEMP_MEAN_2' ,
               'HR_MEAN_3',
               'RESP_MEAN_3',
               'ABPSYS_MEAN_3',
               'ABPDIAS_MEAN_3',
               'ABPMEAN_MEAN_3',
               'SPO2_MEAN_3',
               'TEMP_MEAN_3' ,
               'DIFF_HR_MEAN_1',
               'DIFF_RESP_MEAN_1',
               'DIFF_ABPSYS_MEAN_1',
               'DIFF_ABPDIAS_MEAN_1',
               'DIFF_ABPMEAN_MEAN_1',
               'DIFF_SPO2_MEAN_1',
               'DIFF_TEMP_MEAN_1',
               'DIFF_HR_MEAN_2',
               'DIFF_RESP_MEAN_2',
               'DIFF_ABPSYS_MEAN_2',
               'DIFF_ABPDIAS_MEAN_2',
               'DIFF_ABPMEAN_MEAN_2',
               'DIFF_SPO2_MEAN_2',
               'DIFF_TEMP_MEAN_2',
               'SOFA_MEAN'] 

try:
  df_features.drop(df_features.index, inplace=True)
except:
  print('df_features does not exists')

df_features =pd.DataFrame(columns=feature_cols);

for subject_id in subject_ids:
  curr_idx = df_features.shape[0]
  #df_icuintime_subjectid = df_icutime[df_icutime['subject_id'] == subject_id] 

  icu_intime = df_icutime.loc[df_icutime.subject_id==subject_id , 'intime'].values[0]
  sepsis_onsettime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepsis_onsettime'].values[0]
  shock_onsetttime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepstic_shock_onsettime'].values[0]
  print(shock_onsetttime)

  df_tsdata_subjectid_entire_9h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=9)) )  )]
  df_tsdata_subjectid_first_3h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=3)) )  )]
  df_tsdata_subjectid_next_3h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] > (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=3))   ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=6)) )  )]
  df_tsdata_subjectid_next_next_3h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] > (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=6))   ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=9)) )  )]

  #df_tsdata_subjectid_first_1h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=9)) )  )]
    
  #df_tsdata_subjectid_first_1h = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=1)) )  )]
  
  #df_tsdata_subjectid_first_20h = df_all251_withTemp_cleaned_MVimputed[(df_all251_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all251_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all251_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=20)) )  )]

  #df_tsdata_subjectid_entire_31h = df_all251_withTemp_cleaned_MVimputed[(df_all251_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all251_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all251_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=31)) )  )]
  
  #data_test = df_all404_withTemp_cleaned_MVimputed[(df_all404_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) ]
  #print(data_test[['TIME','HR','RESP','ABPSYS','TEMP']]) # 
  df_features.loc[curr_idx,'SUBJECT_ID'] = subject_id
  df_features.loc[curr_idx,'SEPSIS_ONSETTIME'] = sepsis_onsettime
  df_features.loc[curr_idx,'SEPSIS_SHOCK_ONSETTIME'] = shock_onsetttime

  if str(shock_onsetttime) != 'nan':
    df_features.loc[curr_idx,'HAS_SHOCK'] = 1
  else:
    df_features.loc[curr_idx,'HAS_SHOCK'] = 0

  df_features.loc[curr_idx,'SOFA_MEAN'] = df_tsdata_subjectid_entire_9h['SOFA_SCORE'].mean()
  # CALCULATING MEANS for first 3 hours of data i.e. from sepsis onset time till sepsis onset time + 3 h
  df_features.loc[curr_idx,'HR_MEAN_1'] = df_tsdata_subjectid_first_3h['HR'].mean()
  df_features.loc[curr_idx,'RESP_MEAN_1'] = df_tsdata_subjectid_first_3h['RESP'].mean()
  df_features.loc[curr_idx,'ABPSYS_MEAN_1'] = df_tsdata_subjectid_first_3h['ABPSYS'].mean()
  df_features.loc[curr_idx,'ABPDIAS_MEAN_1'] = df_tsdata_subjectid_first_3h['ABPDIAS'].mean()
  df_features.loc[curr_idx,'ABPMEAN_MEAN_1'] = df_tsdata_subjectid_first_3h['ABPMEAN'].mean()
  df_features.loc[curr_idx,'SPO2_MEAN_1'] = df_tsdata_subjectid_first_3h['SPO2'].mean()
  df_features.loc[curr_idx,'TEMP_MEAN_1'] = df_tsdata_subjectid_first_3h['TEMP'].mean()


  # CALCULATING MEANS for first 3 hours of data i.e. from sepsis onset time + 3 h till SO + 6 hours
  df_features.loc[curr_idx,'HR_MEAN_2'] = df_tsdata_subjectid_next_3h['HR'].mean()
  df_features.loc[curr_idx,'RESP_MEAN_2'] = df_tsdata_subjectid_next_3h['RESP'].mean()
  df_features.loc[curr_idx,'ABPSYS_MEAN_2'] = df_tsdata_subjectid_next_3h['ABPSYS'].mean()
  df_features.loc[curr_idx,'ABPDIAS_MEAN_2'] = df_tsdata_subjectid_next_3h['ABPDIAS'].mean()
  df_features.loc[curr_idx,'ABPMEAN_MEAN_2'] = df_tsdata_subjectid_next_3h['ABPMEAN'].mean()
  df_features.loc[curr_idx,'SPO2_MEAN_2'] = df_tsdata_subjectid_next_3h['SPO2'].mean()
  df_features.loc[curr_idx,'TEMP_MEAN_2'] = df_tsdata_subjectid_next_3h['TEMP'].mean()

  # CALCULATING MEANS for first 3 hours of data i.e. from sepsis onset time + 6 h till SO + 9 hours
  df_features.loc[curr_idx,'HR_MEAN_3'] = df_tsdata_subjectid_next_next_3h['HR'].mean()
  df_features.loc[curr_idx,'RESP_MEAN_3'] = df_tsdata_subjectid_next_next_3h['RESP'].mean()
  df_features.loc[curr_idx,'ABPSYS_MEAN_3'] = df_tsdata_subjectid_next_next_3h['ABPSYS'].mean()
  df_features.loc[curr_idx,'ABPDIAS_MEAN_3'] = df_tsdata_subjectid_next_next_3h['ABPDIAS'].mean()
  df_features.loc[curr_idx,'ABPMEAN_MEAN_3'] = df_tsdata_subjectid_next_next_3h['ABPMEAN'].mean()
  df_features.loc[curr_idx,'SPO2_MEAN_3'] = df_tsdata_subjectid_next_next_3h['SPO2'].mean()
  df_features.loc[curr_idx,'TEMP_MEAN_3'] = df_tsdata_subjectid_next_next_3h['TEMP'].mean()

  # CALCULATING DIFFERENCE IN MEANS BETWEEN 1 AND 2 ND WINDOW
  df_features.loc[curr_idx,'DIFF_HR_MEAN_1'] =  df_tsdata_subjectid_next_3h['HR'].mean() - df_tsdata_subjectid_first_3h['HR'].mean()
  df_features.loc[curr_idx,'DIFF_RESP_MEAN_1'] = df_tsdata_subjectid_next_3h['RESP'].mean() - df_tsdata_subjectid_first_3h['RESP'].mean()
  df_features.loc[curr_idx,'DIFF_ABPSYS_MEAN_1'] = df_tsdata_subjectid_next_3h['ABPSYS'].mean()- df_tsdata_subjectid_first_3h['ABPSYS'].mean()
  df_features.loc[curr_idx,'DIFF_ABPDIAS_MEAN_1'] = df_tsdata_subjectid_next_3h['ABPDIAS'].mean()- df_tsdata_subjectid_first_3h['ABPDIAS'].mean()
  df_features.loc[curr_idx,'DIFF_ABPMEAN_MEAN_1'] = df_tsdata_subjectid_next_3h['ABPMEAN'].mean()- df_tsdata_subjectid_first_3h['ABPMEAN'].mean()
  df_features.loc[curr_idx,'DIFF_SPO2_MEAN_1'] = df_tsdata_subjectid_next_3h['SPO2'].mean()- df_tsdata_subjectid_first_3h['SPO2'].mean()
  df_features.loc[curr_idx,'DIFF_TEMP_MEAN_1'] = df_tsdata_subjectid_next_3h['TEMP'].mean()- df_tsdata_subjectid_first_3h['TEMP'].mean()

  # CALCULATING DIFFERENCE IN MEANS BETWEEN 2 AND 3 RD WINDOW
  df_features.loc[curr_idx,'DIFF_HR_MEAN_2'] =  df_tsdata_subjectid_next_next_3h['HR'].mean() - df_tsdata_subjectid_next_3h['HR'].mean()
  df_features.loc[curr_idx,'DIFF_RESP_MEAN_2'] = df_tsdata_subjectid_next_next_3h['RESP'].mean() - df_tsdata_subjectid_next_3h['RESP'].mean()
  df_features.loc[curr_idx,'DIFF_ABPSYS_MEAN_2'] = df_tsdata_subjectid_next_next_3h['ABPSYS'].mean()- df_tsdata_subjectid_next_3h['ABPSYS'].mean()
  df_features.loc[curr_idx,'DIFF_ABPDIAS_MEAN_2'] = df_tsdata_subjectid_next_next_3h['ABPDIAS'].mean()- df_tsdata_subjectid_next_3h['ABPDIAS'].mean()
  df_features.loc[curr_idx,'DIFF_ABPMEAN_MEAN_2'] = df_tsdata_subjectid_next_next_3h['ABPMEAN'].mean()- df_tsdata_subjectid_next_3h['ABPMEAN'].mean()
  df_features.loc[curr_idx,'DIFF_SPO2_MEAN_2'] = df_tsdata_subjectid_next_next_3h['SPO2'].mean()- df_tsdata_subjectid_next_3h['SPO2'].mean()
  df_features.loc[curr_idx,'DIFF_TEMP_MEAN_2'] = df_tsdata_subjectid_next_next_3h['TEMP'].mean()- df_tsdata_subjectid_next_3h['TEMP'].mean()



  icu_intime='';
  sepsis_onsettime='';
  shock_onsetttime = '';

  df_tsdata_subjectid_first_3h.drop(df_tsdata_subjectid_first_3h.index, inplace = True)
  df_tsdata_subjectid_next_3h.drop(df_tsdata_subjectid_next_3h.index, inplace = True)
  df_tsdata_subjectid_next_next_3h.drop(df_tsdata_subjectid_next_next_3h.index, inplace = True)

  #df_tsdata_subjectid_first_1h.drop(df_tsdata_subjectid_first_1h.index, inplace = True)
  #df_tsdata_subjectid_first_10h.drop(df_tsdata_subjectid_first_10h.index, inplace=True)
  #df_tsdata_subjectid_first_20h.drop(df_tsdata_subjectid_first_20h.index, inplace=True) 
  #df_tsdata_subjectid_entire_31h.drop(df_tsdata_subjectid_entire_31h.index, inplace=True)  
  #print(df_features)

print(df_features.shape)
print(df_features.columns)

from sklearn.model_selection import train_test_split
import statsmodels.api as sm
import statsmodels.formula.api as smf

x = df_features[['HR_MEAN_1',
               'RESP_MEAN_1',
               'ABPSYS_MEAN_1',
               'ABPDIAS_MEAN_1',
               'ABPMEAN_MEAN_1',
               'SPO2_MEAN_1',
               'TEMP_MEAN_1' ,
               'HR_MEAN_2',
               'RESP_MEAN_2',
               'ABPSYS_MEAN_2',
               'ABPDIAS_MEAN_2',
               'ABPMEAN_MEAN_2',
               'SPO2_MEAN_2',
               'TEMP_MEAN_2' ,
               'HR_MEAN_3',
               'RESP_MEAN_3',
               'ABPSYS_MEAN_3',
               'ABPDIAS_MEAN_3',
               'ABPMEAN_MEAN_3',
               'SPO2_MEAN_3',
               'TEMP_MEAN_3' ,
               'DIFF_HR_MEAN_1',
               'DIFF_RESP_MEAN_1',
               'DIFF_ABPSYS_MEAN_1',
               'DIFF_ABPDIAS_MEAN_1',
               'DIFF_ABPMEAN_MEAN_1',
               'DIFF_SPO2_MEAN_1',
               'DIFF_TEMP_MEAN_1',
               'DIFF_HR_MEAN_2',
               'DIFF_RESP_MEAN_2',
               'DIFF_ABPSYS_MEAN_2',
               'DIFF_ABPDIAS_MEAN_2',
               'DIFF_ABPMEAN_MEAN_2',
               'DIFF_SPO2_MEAN_2',
               'DIFF_TEMP_MEAN_2' ,
               'SOFA_MEAN']]

x = x.apply(pd.to_numeric)

y = df_features['HAS_SHOCK']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=42)
print(x_train)
print(y_train)


# building GLM Bionomial model and training it

glm = smf.glm(formula='SOFA_MEAN ~ HR_MEAN_1 + RESP_MEAN_1 + ABPSYS_MEAN_1 + ABPDIAS_MEAN_1 + ABPMEAN_MEAN_1 + SPO2_MEAN_1 + TEMP_MEAN_1 + HR_MEAN_2 + RESP_MEAN_2 + ABPSYS_MEAN_2 + ABPDIAS_MEAN_2 + ABPMEAN_MEAN_2 + SPO2_MEAN_2 + TEMP_MEAN_2 +  HR_MEAN_3 + RESP_MEAN_3 + ABPSYS_MEAN_3 + ABPDIAS_MEAN_3 + ABPMEAN_MEAN_3 + SPO2_MEAN_3 + TEMP_MEAN_3 + DIFF_HR_MEAN_1 + DIFF_RESP_MEAN_1 + DIFF_ABPSYS_MEAN_1 + DIFF_ABPDIAS_MEAN_1 + DIFF_ABPMEAN_MEAN_1 + DIFF_SPO2_MEAN_1 + DIFF_TEMP_MEAN_1 + DIFF_HR_MEAN_2 + DIFF_RESP_MEAN_2 + DIFF_ABPSYS_MEAN_2 + DIFF_ABPDIAS_MEAN_2 + DIFF_ABPMEAN_MEAN_2 + DIFF_SPO2_MEAN_2 + DIFF_TEMP_MEAN_2 ', data = x_train, family = sm.families.Poisson())
glm_regression_model = glm.fit()

print(y_test)

# building GLM Bionomial model and training it
import statsmodels.api as sm

y_train =  y_train.astype(int)

x_train = np.asarray(x_train)

glm_bionomial = sm.GLM(y_train, x_train, family=sm.families.Binomial())
glm_bio_model = glm_bionomial.fit()

from sklearn.metrics import mean_squared_error

regression_test = x_test[['HR_MEAN_1',
               'RESP_MEAN_1',
               'ABPSYS_MEAN_1',
               'ABPDIAS_MEAN_1',
               'ABPMEAN_MEAN_1',
               'SPO2_MEAN_1',
               'TEMP_MEAN_1' ,
               'HR_MEAN_2',
               'RESP_MEAN_2',
               'ABPSYS_MEAN_2',
               'ABPDIAS_MEAN_2',
               'ABPMEAN_MEAN_2',
               'SPO2_MEAN_2',
               'TEMP_MEAN_2' ,
               'HR_MEAN_3',
               'RESP_MEAN_3',
               'ABPSYS_MEAN_3',
               'ABPDIAS_MEAN_3',
               'ABPMEAN_MEAN_3',
               'SPO2_MEAN_3',
               'TEMP_MEAN_3' ,
               'DIFF_HR_MEAN_1',
               'DIFF_RESP_MEAN_1',
               'DIFF_ABPSYS_MEAN_1',
               'DIFF_ABPDIAS_MEAN_1',
               'DIFF_ABPMEAN_MEAN_1',
               'DIFF_SPO2_MEAN_1',
               'DIFF_TEMP_MEAN_1',
               'DIFF_HR_MEAN_2',
               'DIFF_RESP_MEAN_2',
               'DIFF_ABPSYS_MEAN_2',
               'DIFF_ABPDIAS_MEAN_2',
               'DIFF_ABPMEAN_MEAN_2',
               'DIFF_SPO2_MEAN_2',
               'DIFF_TEMP_MEAN_2' ]]
#testing on sofa regression 
predictions = glm_regression_model.predict(regression_test)
actual_sofa = x_test['SOFA_MEAN']
rms = np.sqrt(mean_squared_error(actual_sofa, predictions))
print('ROOT MEAN SQUARE ERROR FOR SOFA_MEAN_1 : ',rms_1 )

x_test['SOFA_MEAN'] = predictions


print(x_test)

#x_test['PREDCITED_SOFA'] = predictions
x_test = x_test[['HR_MEAN_1',
               'RESP_MEAN_1',
               'ABPSYS_MEAN_1',
               'ABPDIAS_MEAN_1',
               'ABPMEAN_MEAN_1',
               'SPO2_MEAN_1',
               'TEMP_MEAN_1' ,
               'HR_MEAN_2',
               'RESP_MEAN_2',
               'ABPSYS_MEAN_2',
               'ABPDIAS_MEAN_2',
               'ABPMEAN_MEAN_2',
               'SPO2_MEAN_2',
               'TEMP_MEAN_2' ,
               'HR_MEAN_3',
               'RESP_MEAN_3',
               'ABPSYS_MEAN_3',
               'ABPDIAS_MEAN_3',
               'ABPMEAN_MEAN_3',
               'SPO2_MEAN_3',
               'TEMP_MEAN_3' ,
               'DIFF_HR_MEAN_1',
               'DIFF_RESP_MEAN_1',
               'DIFF_ABPSYS_MEAN_1',
               'DIFF_ABPDIAS_MEAN_1',
               'DIFF_ABPMEAN_MEAN_1',
               'DIFF_SPO2_MEAN_1',
               'DIFF_TEMP_MEAN_1',
               'DIFF_HR_MEAN_2',
               'DIFF_RESP_MEAN_2',
               'DIFF_ABPSYS_MEAN_2',
               'DIFF_ABPDIAS_MEAN_2',
               'DIFF_ABPMEAN_MEAN_2',
               'DIFF_SPO2_MEAN_2',
               'DIFF_TEMP_MEAN_2',
               'SOFA_MEAN']]
print(x_test)

y_test= y_test.astype(int)
print(y_test)


#testing on bionomial regression for classification
Class_predictions = glm_bio_model.predict(x_test)
print(glm_bio_model.model.endog_names)

print(Class_predictions)
print(y_test)

from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve

fpr, tpr, thresholds = metrics.roc_curve(y_test, Class_predictions)
pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')
pyplot.plot(fpr, tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
pyplot.legend()
# show the plot
pyplot.show()
gmeans = sqrt(tpr * (1-fpr))
ix = argmax(gmeans)
print('Best Threshold according to the G-Mean=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))

########## calculating best threshold according to the best F1-score:

precision, recall, thresholds = precision_recall_curve(y_test, Class_predictions)
# convert to f score
fscore = (2 * precision * recall) / (precision + recall)
# locate the index of the largest f score
ix = argmax(fscore)
print('Best Threshold according to the F-Score=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))


########## calculating best threshold according to the  Youden’s J statistic.:
fpr, tpr, thresholds = metrics.roc_curve(y_test, Class_predictions)
J = tpr - fpr
ix = argmax(J)
best_thresh = thresholds[ix]
print('Best Threshold according to the Youden’s J statistic=%f' % (best_thresh))

from sklearn.metrics import confusion_matrix, classification_report
y_pred = [ 0 if x < 0.727 else 1 for x in Class_predictions]
print(classification_report(y_test, 
                            y_pred, 
                            digits = 3))
print(y_test)
print(y_pred)

from sklearn import metrics
import seaborn as sns
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))
print("F-Score:",metrics.f1_score(y_test, y_pred))

"""
Accuracy: 0.7142857142857143
Precision: 0.6538461538461539
Recall: 0.5666666666666667
F-Score: 0.6071428571428571

"""