# -*- coding: utf-8 -*-
"""33_forEachPatient_BASIC_streaming_WITH_ALL_FEATURES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EBCPO2VVuQTGWCgHj07jdLyXJQ8COfjv
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import pandas as pd
import io
import pandas as pd
from IPython.display import display
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import os
import shutil
import posixpath
import urllib.request
import datetime
from collections import namedtuple

pd.set_option('display.max_rows', 50000)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)
pd.set_option('max_colwidth', 800)

drive.mount('/content/gdrive')

# Download All Time series data for 404 patients.

df_all256_withTemp = pd.read_csv('/content/gdrive/My Drive/Master thesis/df_ts_records_all256SepsisPatients(lessThan20%Missing)_fromSepsisOnset_ShockOnset_or_sepsisOnsetPlus31h_WITH_TEMP_SOFA.csv')
df_all256_withTemp['TIME'] =  pd.to_datetime(df_all256_withTemp['TIME'])
print(df_all256_withTemp.shape)
print(df_all256_withTemp.columns)

#cleaning data :  removing all negative values

df_all256_withTemp.HR = df_all256_withTemp.HR.mask(df_all256_withTemp.HR < 0)

df_all256_withTemp.RESP = df_all256_withTemp.RESP.mask(df_all256_withTemp.RESP < 0)

df_all256_withTemp.ABPSYS = df_all256_withTemp.ABPSYS.mask(df_all256_withTemp.ABPSYS < 0)

df_all256_withTemp.ABPDIAS = df_all256_withTemp.ABPDIAS.mask(df_all256_withTemp.ABPDIAS < 0)

df_all256_withTemp.ABPMEAN = df_all256_withTemp.ABPMEAN.mask(df_all256_withTemp.ABPMEAN < 0)

df_all256_withTemp.SPO2 = df_all256_withTemp.SPO2.mask(df_all256_withTemp.SPO2 < 0)

df_all256_withTemp.TEMP = df_all256_withTemp.TEMP.mask(df_all256_withTemp.TEMP < 0)


df_all256_withTemp.SOFA_SCORE = df_all256_withTemp.SOFA_SCORE.mask(df_all256_withTemp.SOFA_SCORE < 0)


df_all256_withTemp.RESP_SOFA = df_all256_withTemp.RESP_SOFA.mask(df_all256_withTemp.RESP_SOFA < 0)


df_all256_withTemp.LIVER_SOFA = df_all256_withTemp.LIVER_SOFA.mask(df_all256_withTemp.LIVER_SOFA < 0)


df_all256_withTemp.RENAL_SOFA = df_all256_withTemp.RENAL_SOFA.mask(df_all256_withTemp.RENAL_SOFA < 0)


df_all256_withTemp.CARDIO_SOFA = df_all256_withTemp.CARDIO_SOFA.mask(df_all256_withTemp.CARDIO_SOFA < 0)


df_all256_withTemp.CNS_SOFA = df_all256_withTemp.CNS_SOFA.mask(df_all256_withTemp.CNS_SOFA < 0)


df_all256_withTemp.COAG_SOFA = df_all256_withTemp.COAG_SOFA.mask(df_all256_withTemp.COAG_SOFA < 0)

# Missing value imputation by carry forward scheme
df_all256_withTemp_cleaned_MVimputed = df_all256_withTemp.ffill().bfill()

df_all256_withTemp_cleaned_MVimputed.HR = df_all256_withTemp_cleaned_MVimputed.HR.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.RESP = df_all256_withTemp_cleaned_MVimputed.RESP.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPSYS = df_all256_withTemp_cleaned_MVimputed.ABPSYS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPDIAS = df_all256_withTemp_cleaned_MVimputed.ABPDIAS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPMEAN = df_all256_withTemp_cleaned_MVimputed.ABPMEAN.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.SPO2 = df_all256_withTemp_cleaned_MVimputed.SPO2.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.TEMP = df_all256_withTemp_cleaned_MVimputed.TEMP.round(decimals=4)


df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE = df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA = df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA = df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.COAG_SOFA = df_all256_withTemp_cleaned_MVimputed.COAG_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA = df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CNS_SOFA = df_all256_withTemp_cleaned_MVimputed.CNS_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RESP_SOFA = df_all256_withTemp_cleaned_MVimputed.RESP_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed['TIME'] =  pd.to_datetime(df_all256_withTemp_cleaned_MVimputed['TIME'])

print(df_all256_withTemp_cleaned_MVimputed[df_all256_withTemp_cleaned_MVimputed.isnull().any(axis=1)])

subject_ids = df_all256_withTemp_cleaned_MVimputed.SUBJECT_ID.unique()
print(len(subject_ids))

for i in [41589 , 52875,  81849]:
    subject_ids = np.delete(subject_ids,np.where(subject_ids==i))

print(subject_ids)
print(len(subject_ids))

from google.colab import files
uploaded = files.upload()

df_icutime = pd.read_csv(io.BytesIO(uploaded['Only_AllSepsisPatients_with_MissingData_FromSepsisOnset_ToShockOnset_or_SepsisOnset+31h.csv']))
print (df_icutime.columns)
#df_icutime = df_icutime[['subject_id','icustay_id','intime','outtime','sepsis_onsettime']]
#print (df_icutime.columns)
"""
df_icutime['intime'] =  pd.to_datetime(df_icutime['intime'])
df_icutime['outtime'] =  pd.to_datetime(df_icutime['outtime'])
"""

import seaborn as sns
data_corr = df_all256_withTemp_cleaned_MVimputed[['HR', 'SPO2', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'RESP', 'TEMP','SOFA_SCORE']]
corr = data_corr.corr()# calculating the correlation between the above vital signs
sns.heatmap(corr, square=True) # plotting the correlation

import scipy
import collections
from scipy.stats import entropy

feature_cols= ['TIME','ICUSTAY_ID','SUBJECT_ID','SEPSIS_ONSETTIME','SEPSIS_SHOCK_ONSETTIME','HAS_SHOCK','HOURS_BETWEEN',
               'HR',
               'RESP',
               'ABPSYS',
               'ABPDIAS',
               'ABPMEAN',
               'SPO2',
               'TEMP' ,
               'SOFA_SCORE',

               'HR_STD',
               'RESP_STD',
               'ABPSYS_STD',
               'ABPDIAS_STD',
               'ABPMEAN_STD',
               'SPO2_STD',
               'TEMP_STD',
               'SOFA_SCORE_STD',
               
               'HR_ENT',
               'RESP_ENT',
               'ABPSYS_ENT',
               'ABPDIAS_ENT',
               'ABPMEAN_ENT',
               'SPO2_ENT',
               'TEMP_ENT',
               'SOFA_SCORE_ENT',

               'ABPDIAS_HR_CORR',
               'RESP_HR_CORR',
               'ABPDIAS_ABPSYS_CORR',
               'ABPMEAN_ABPSYS_CORR',
               'ABPMEAN_ABPDIAS_CORR',

                'HR_MIN',
                'RESP_MIN',
                'SPO2_MIN',
                'TEMP_MIN',
                'SOFA_SCORE_MIN',
                'ABPSYS_MIN',
                'ABPDIAS_MIN',
                'ABPMEAN_MIN',
                'HR_MAX',
                'RESP_MAX',
                'SPO2_MAX',
                'TEMP_MAX',
                'SOFA_SCORE_MAX',
                'ABPSYS_MAX',
                'ABPDIAS_MAX',
                'ABPMEAN_MAX',

               'HR_DIFF',
               'RESP_DIFF',
               'ABPSYS_DIFF',
               'ABPDIAS_DIFF',
               'ABPMEAN_DIFF',
               'SPO2_DIFF',
               'TEMP_DIFF' ,
               'SOFA_SCORE_DIFF'
               ] 
              



temp_feature_cols= ['TIME',
               'HR',
               'RESP',
               'ABPSYS',
               'ABPDIAS',
               'ABPMEAN',
               'SPO2',
               'TEMP',
               'SOFA_SCORE'
               ] 


try:
  df_features.drop(df_features.index, inplace=True)
except:
  print('df_features does not exists')

df_features  =  pd.DataFrame(columns=feature_cols);

for subject_id in subject_ids:
  curr_idx = df_features.shape[0]
  

  icustay_id = df_icutime.loc[df_icutime.subject_id==subject_id , 'icustay_id'].values[0]

  icu_intime = df_icutime.loc[df_icutime.subject_id==subject_id , 'intime'].values[0]
  sepsis_onsettime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepsis_onsettime'].values[0]

  shock_onsetttime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepstic_shock_onsettime'].values[0]

  if str(shock_onsetttime) == 'nan':
    
    has_shock = 0 ;
    #print('not a shock patient')
    df_tsdata_subjectid_entireTimeBeforeShock = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=31)) )  )]
    skip = 31
  else:
    has_shock = 1 ;

    datetime_shock_date = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S').date()
    datetime_shock_time_hour  = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S').time().hour
    df_tsdata_subjectid_entireTimeBeforeShock = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S')) )  )]
    hours_between = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S')  - datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') 
    duration_in_s = hours_between.total_seconds()
    q, r = divmod(duration_in_s, 3600)
    skip = int(q + int(bool(r)))

  
  
  first_row = df_tsdata_subjectid_entireTimeBeforeShock.iloc[0,:]
  
  base_min = int(first_row['TIME'].strftime('%M') )

  df_tsdata_subjectid_entireTimeBeforeShock = df_tsdata_subjectid_entireTimeBeforeShock[temp_feature_cols]
  df_features_temp =pd.DataFrame(columns=temp_feature_cols)
  
  """

  #for mean per hour
  df_features_temp = df_tsdata_subjectid_entireTimeBeforeShock.resample('60min',base=base_min,  on='TIME').mean()
  print('after aggregating mean : ', df_features_temp.shape[0])
  


  # for standard deviation
  df_features_temp_std = df_tsdata_subjectid_entireTimeBeforeShock.resample('60min',base=base_min,  on='TIME').std()

  df_features_temp_std =  df_features_temp_std[['HR','RESP','ABPSYS', 'ABPDIAS','ABPMEAN','SPO2','TEMP', 'SOFA_SCORE']]

  df_features_temp_std.columns = ['HR_STD','RESP_STD','ABPSYS_STD','ABPDIAS_STD','ABPMEAN_STD','SPO2_STD','TEMP_STD','SOFA_SCORE_STD']
  df_features_temp = pd.concat([df_features_temp, df_features_temp_std], axis=1)

  print('after aggregating mean annd std : ', df_features_temp.shape[0])
  print(df_features_temp)

  #print(' df_features_temp after concatenation with std')
  # for calculation of entropy
  """
  #q, r = divmod(df_tsdata_subjectid_entireTimeBeforeShock.shape[0], 60)
  #skip = q + int(bool(r)) # rounds to next greater integer (always ceiling)
  #print(skip)
  """
  skip = df_features_temp.shape[0]
  #print('printing skip : ', skip)

  start_window_idx = 0
  end_window_idx = 60
  """
  #For mean calculation
  hr_mean_list = []
  resp_mean_list = []
  spo2_mean_list = []
  temp_mean_list = []
  sofa_mean_list = []
  abpsys_mean_list = []
  abpdias_mean_list = []
  abpmean_mean_list = []

  hr_mean = '';
  resp_mean = '';
  spo2_mean = '';
  temp_mean = '';
  sofa_mean = '';
  abpsys_mean = '';
  abpdias_mean = '';
  abpmean_mean = '';

  # for std calculation
  hr_std_list = []
  resp_std_list = []
  spo2_std_list = []
  temp_std_list = []
  sofa_std_list = []
  abpsys_std_list = []
  abpdias_std_list = []
  abpmean_std_list = []

  hr_std = '';
  resp_std = '';
  spo2_std = '';
  temp_std = '';
  sofa_std = '';
  abpsys_std = '';
  abpdias_std = '';
  abpmean_std = '';


  #for entropy calculation
  hr_entropy_list=[]
  resp_entropy_list = []
  spo2_entropy_list = []
  temp_entropy_list = []
  sofa_entropy_list = []
  abpsys_entropy_list = []
  abpdias_entropy_list = []
  abpmean_entropy_list = []

  hr_entropy = '';
  resp_entropy = '';
  spo2_entropy = '';
  temp_entropy = '';
  sofa_entropy = '';
  abpsys_entropy = '';
  abpdias_entropy = '';
  abpmean_entropy = '';

  # for correlation calculation
  abpdias_hr_corr_list = [];
  resp_hr_corr_list = [];
  abpdias_abpsys_corr_list = [];
  abpmean_abpsys_corr_list = [];
  abpmean_abpdias_corr_list = [];


  # for min calculation
  hr_min_list=[]
  resp_min_list = []
  spo2_min_list = []
  temp_min_list = []
  sofa_min_list = []
  abpsys_min_list = []
  abpdias_min_list = []
  abpmean_min_list = []

  hr_min = '';
  resp_min = '';
  spo2_min = '';
  temp_min = '';
  sofa_min = '';
  abpsys_min = '';
  abpdias_min = '';
  abpmean_min = '';

  # for max calculation
  hr_max_list=[]
  resp_max_list = []
  spo2_max_list = []
  temp_max_list = []
  sofa_max_list = []
  abpsys_max_list = []
  abpdias_max_list = []
  abpmean_max_list = []

  hr_max = '';
  resp_max = '';
  spo2_max = '';
  temp_max = '';
  sofa_max = '';
  abpsys_max = '';
  abpdias_max = '';
  abpmean_max = '';

  #for time
  time_list = [];
  has_shock_list = [] ;

  init_time = first_row['TIME']
  end_time = first_row['TIME'] + datetime.timedelta(minutes =60)


  for i in range(skip):
    
    #print('start_window_time : ', init_time)
    #print('end_window_time : ', end_time)

    #df_subset = df_tsdata_subjectid_entireTimeBeforeShock.iloc[start_window_idx:end_window_idx,:]
    df_subset = df_tsdata_subjectid_entireTimeBeforeShock[(df_tsdata_subjectid_entireTimeBeforeShock['TIME'] >= init_time) & (df_tsdata_subjectid_entireTimeBeforeShock['TIME'] < end_time) ]
  
    if ( has_shock == 1 ) & (init_time.date() == datetime_shock_date)  & ( init_time.time().hour >= datetime_shock_time_hour) :
      time_has_shock = 1
    else:
      time_has_shock = 0
    
    has_shock_list.append(time_has_shock)

    
    hr_mean = '';
    resp_mean = '';
    spo2_mean = '';
    temp_mean = '';
    sofa_mean = '';
    abpsys_mean = '';
    abpdias_mean = '';
    abpmean_mean = '';


    hr_std = '';
    resp_std = '';
    spo2_std = '';
    temp_std = '';
    sofa_std = '';
    abpsys_std = '';
    abpdias_std = '';
    abpmean_std = '';


    hr_entropy = '';
    resp_entropy = '';
    spo2_entropy = '';
    temp_entropy = '';
    sofa_entropy = '';
    abpsys_entropy = '';
    abpdias_entropy = '';
    abpmean_entropy = '';

    abpdias_hr_corr = '';
    resp_hr_corr= '';
    abpdias_abpsys_corr= '';
    abpmean_abpsys_corr= '';
    abpmean_abpdias_corr= '';


    hr_min = '';
    resp_min = '';
    spo2_min = '';
    temp_min = '';
    sofa_min = '';
    abpsys_min = '';
    abpdias_min = '';
    abpmean_min = '';


    hr_max = '';
    resp_max = '';
    spo2_max = '';
    temp_max = '';
    sofa_max = '';
    abpsys_max = '';
    abpdias_max = '';
    abpmean_max = '';


    #extracting series for all vitals + sofa
    hr_series = df_subset.HR
    resp_series = df_subset.RESP
    spo2_series = df_subset.SPO2
    sofa_series =df_subset.SOFA_SCORE
    temp_series = df_subset.TEMP
    abpsys_series = df_subset.ABPSYS
    abpdias_series = df_subset.ABPDIAS
    abpmean_series = df_subset.ABPMEAN

    # other way to calculate the entropy
    #hr_entropy = sample_entropy(hr_series) # from tsfresh package
    #hr_entropy_list.append(hr_entropy)

    
    hr_data = hr_series.value_counts()           # counts occurrence of each value
    hr_entropy = scipy.stats.entropy(hr_data)  # get entropy from counts
    hr_entropy_list.append(hr_entropy) 
    hr_min = hr_series.min()
    hr_min_list.append(hr_min)
    hr_max = hr_series.max()
    hr_max_list.append(hr_max)
    ##### for mean and std
    hr_mean = hr_series.mean()
    hr_mean_list.append(hr_mean)
    hr_std = hr_series.std()
    hr_std_list.append(hr_std)





    resp_data = resp_series.value_counts()           # counts occurrence of each value
    resp_entropy = scipy.stats.entropy(resp_data)  # get entropy from counts
    resp_entropy_list.append(resp_entropy)
    resp_min = resp_series.min()
    resp_min_list.append(resp_min)
    resp_max = resp_series.max()
    resp_max_list.append(resp_max)
    ### for mmean and std
    resp_mean = resp_series.mean()
    resp_mean_list.append(resp_mean)
    resp_std = resp_series.std()
    resp_std_list.append(resp_std)


    spo2_data = spo2_series.value_counts()           # counts occurrence of each value
    spo2_entropy = scipy.stats.entropy(spo2_data)  # get entropy from counts
    spo2_entropy_list.append(spo2_entropy)
    spo2_min = spo2_series.min()
    spo2_min_list.append(spo2_min)
    spo2_max = spo2_series.max()
    spo2_max_list.append(spo2_max)
    ### for mmean and std
    spo2_mean = spo2_series.mean()
    spo2_mean_list.append(spo2_mean)
    spo2_std = spo2_series.std()
    spo2_std_list.append(spo2_std)


    temp_data = temp_series.value_counts()           # counts occurrence of each value
    temp_entropy = scipy.stats.entropy(temp_data)  # get entropy from counts
    temp_entropy_list.append(temp_entropy)
    temp_min = temp_series.min()
    temp_min_list.append(temp_min)
    temp_max = temp_series.max()
    temp_max_list.append(temp_max)
    ### for mmean and std
    temp_mean = temp_series.mean()
    temp_mean_list.append(temp_mean)
    temp_std = temp_series.std()
    temp_std_list.append(temp_std)


    sofa_data = sofa_series.value_counts()           # counts occurrence of each value
    sofa_entropy = scipy.stats.entropy(sofa_data)  # get entropy from counts
    sofa_entropy_list.append(sofa_entropy)
    sofa_min = sofa_series.min()
    sofa_min_list.append(sofa_min)
    sofa_max = sofa_series.max()
    sofa_max_list.append(sofa_max)
    ### for mmean and std
    sofa_mean = sofa_series.mean()
    sofa_mean_list.append(sofa_mean)
    sofa_std = sofa_series.std()
    sofa_std_list.append(sofa_std)

    abpsys_data = abpsys_series.value_counts()           # counts occurrence of each value
    abpsys_entropy = scipy.stats.entropy(abpsys_data)  # get entropy from counts
    abpsys_entropy_list.append(abpsys_entropy)
    abpsys_min = abpsys_series.min()
    abpsys_min_list.append(abpsys_min)
    abpsys_max = abpsys_series.max()
    abpsys_max_list.append(abpsys_max)
    ### for mmean and std
    abpsys_mean = abpsys_series.mean()
    abpsys_mean_list.append(abpsys_mean)
    abpsys_std = abpsys_series.std()
    abpsys_std_list.append(abpsys_std)


    abpdias_data = abpdias_series.value_counts()           # counts occurrence of each value
    abpdias_entropy = scipy.stats.entropy(abpdias_data)  # get entropy from counts
    abpdias_entropy_list.append(abpdias_entropy)
    abpdias_min = abpdias_series.min()
    abpdias_min_list.append(abpdias_min)
    abpdias_max = abpdias_series.max()
    abpdias_max_list.append(abpdias_max)
    ### for mmean and std
    abpdias_mean = abpdias_series.mean()
    abpdias_mean_list.append(abpdias_mean)
    abpdias_std = abpdias_series.std()
    abpdias_std_list.append(abpdias_std)


    abpmean_data = abpmean_series.value_counts()           # counts occurrence of each value
    abpmean_entropy = scipy.stats.entropy(abpmean_data)  # get entropy from counts
    abpmean_entropy_list.append(abpmean_entropy)
    abpmean_min = abpmean_series.min()
    abpmean_min_list.append(abpmean_min)
    abpmean_max = abpmean_series.max()
    abpmean_max_list.append(abpmean_max)
    ### for mmean and std
    abpmean_mean = abpmean_series.mean()
    abpmean_mean_list.append(abpmean_mean)
    abpmean_std = abpmean_series.std()
    abpmean_std_list.append(abpmean_std)

    


    abpdias_hr_corr = abpdias_series.corr(hr_series) 
    abpdias_hr_corr_list.append(abpdias_hr_corr);
    
    resp_hr_corr = resp_series.corr(hr_series) 
    resp_hr_corr_list.append(resp_hr_corr);
    

    abpdias_abpsys_corr = abpdias_series.corr(abpsys_series) 
    abpdias_abpsys_corr_list.append(abpdias_abpsys_corr);
    
    abpmean_abpsys_corr = abpmean_series.corr(abpsys_series) 
    abpmean_abpsys_corr_list.append(abpmean_abpsys_corr);
    

    abpmean_abpdias_corr = abpmean_series.corr(abpdias_series) 
    abpmean_abpdias_corr_list.append(abpmean_abpdias_corr);
   
    time_list.append(init_time)

    init_time = end_time # incrementing times for the next window
    end_time = init_time + datetime.timedelta(minutes=60)

    #start_window_idx = end_window_idx 
    #end_window_idx = end_window_idx + 60
    

  #['HR_STD','RESP_STD','ABPSYS_STD','ABPDIAS_STD','ABPMEAN_STD','SPO2_STD','TEMP_STD','SOFA_SCORE_STD']
  #print('df_features_temp lenght: ', df_features_temp.shape)
  #print('hr entrpy list lenght : ', len(hr_entropy_list))

  #for mean and std
  df_features_temp['HR'] = hr_mean_list
  df_features_temp['RESP'] = resp_mean_list
  df_features_temp['ABPSYS'] = abpsys_mean_list
  df_features_temp['ABPDIAS'] = abpdias_mean_list
  df_features_temp['ABPMEAN'] = abpmean_mean_list
  df_features_temp['SPO2'] = spo2_mean_list
  df_features_temp['TEMP'] = temp_mean_list
  df_features_temp['SOFA_SCORE'] = sofa_mean_list

  df_features_temp['HR_STD'] = hr_std_list
  df_features_temp['RESP_STD'] = resp_std_list
  df_features_temp['ABPSYS_STD'] = abpsys_std_list
  df_features_temp['ABPDIAS_STD'] = abpdias_std_list
  df_features_temp['ABPMEAN_STD'] = abpmean_std_list
  df_features_temp['SPO2_STD'] = spo2_std_list
  df_features_temp['TEMP_STD'] = temp_std_list
  df_features_temp['SOFA_SCORE_STD'] = sofa_std_list

  df_features_temp['TIME'] = time_list
  df_features_temp['HR_ENT'] = hr_entropy_list
  df_features_temp['RESP_ENT'] = resp_entropy_list
  df_features_temp['ABPSYS_ENT'] = abpsys_entropy_list
  df_features_temp['ABPDIAS_ENT'] = abpdias_entropy_list
  df_features_temp['ABPMEAN_ENT'] = abpmean_entropy_list
  df_features_temp['SPO2_ENT'] = spo2_entropy_list
  df_features_temp['TEMP_ENT'] = temp_entropy_list
  df_features_temp['SOFA_SCORE_ENT'] = sofa_entropy_list


  df_features_temp['ABPDIAS_HR_CORR'] = abpdias_hr_corr_list
  df_features_temp['RESP_HR_CORR'] = resp_hr_corr_list
  df_features_temp['ABPDIAS_ABPSYS_CORR'] = abpdias_abpsys_corr_list
  df_features_temp['ABPMEAN_ABPSYS_CORR'] = abpmean_abpsys_corr_list
  df_features_temp['ABPMEAN_ABPDIAS_CORR'] = abpmean_abpdias_corr_list
  

  #min 

  df_features_temp['HR_MIN'] = hr_min_list
  df_features_temp['RESP_MIN'] = resp_min_list 
  df_features_temp['SPO2_MIN'] = spo2_min_list 
  df_features_temp['TEMP_MIN'] = temp_min_list 
  df_features_temp['SOFA_SCORE_MIN'] = sofa_min_list 
  df_features_temp['ABPSYS_MIN'] = abpsys_min_list
  df_features_temp['ABPDIAS_MIN'] = abpdias_min_list 
  df_features_temp['ABPMEAN_MIN'] = abpmean_min_list

  #MAX
  df_features_temp['HR_MAX'] = hr_max_list
  df_features_temp['RESP_MAX'] = resp_max_list 
  df_features_temp['SPO2_MAX'] = spo2_max_list 
  df_features_temp['TEMP_MAX'] = temp_max_list 
  df_features_temp['SOFA_SCORE_MAX'] = sofa_max_list 
  df_features_temp['ABPSYS_MAX'] = abpsys_max_list
  df_features_temp['ABPDIAS_MAX'] = abpdias_max_list 
  df_features_temp['ABPMEAN_MAX'] = abpmean_max_list

  
  
  df_features_temp['HR_DIFF']=df_features_temp['HR'] -df_features_temp['HR'].shift(1)
  df_features_temp['RESP_DIFF']=df_features_temp['RESP'] -df_features_temp['RESP'].shift(1)
  df_features_temp['ABPSYS_DIFF']=df_features_temp['ABPSYS'] -df_features_temp['ABPSYS'].shift(1)
  df_features_temp['ABPDIAS_DIFF']=df_features_temp['ABPDIAS'] -df_features_temp['ABPDIAS'].shift(1)
  df_features_temp['ABPMEAN_DIFF']=df_features_temp['ABPMEAN'] -df_features_temp['ABPMEAN'].shift(1)
  df_features_temp['SPO2_DIFF']=df_features_temp['SPO2'] -df_features_temp['SPO2'].shift(1)
  df_features_temp['TEMP_DIFF']=df_features_temp['TEMP'] -df_features_temp['TEMP'].shift(1)
  df_features_temp['SOFA_SCORE_DIFF']=df_features_temp['SOFA_SCORE'] -df_features_temp['SOFA_SCORE'].shift(1)



  df_features_temp['ICUSTAY_ID'] = icustay_id
  df_features_temp['SUBJECT_ID'] = subject_id
  df_features_temp['SEPSIS_ONSETTIME'] = sepsis_onsettime
  df_features_temp['SEPSIS_SHOCK_ONSETTIME'] = shock_onsetttime
  df_features_temp['HOURS_BETWEEN'] = skip
  df_features_temp['HAS_SHOCK'] = has_shock
  #df_features_temp['HAS_SHOCK'] = has_shock_list
  
  
  
  # forward and backward fill the correlation columns
  corr_cols = ['ABPDIAS_HR_CORR', 'RESP_HR_CORR','ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR','ABPMEAN_ABPDIAS_CORR']

  df_features_temp.loc[:,corr_cols] = df_features_temp.loc[:,corr_cols].ffill().bfill()


  

  
  

  icu_intime='';
  sepsis_onsettime='';
  shock_onsetttime = '';
  has_shock ='';
  base_min = '';
  

  
  df_features = df_features.append(df_features_temp);
  df_tsdata_subjectid_entireTimeBeforeShock.drop(df_tsdata_subjectid_entireTimeBeforeShock.index, inplace = True)
  df_features_temp.drop(df_features_temp.index, inplace=True)

print(df_features.columns)
print(df_features.shape)

print(df_features[df_features['SUBJECT_ID']== 69272])

#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])

df_test = df_features[['SUBJECT_ID','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX' ]]

print(df_test[df_test.isnull().any(axis=1)])

#elimninate the nan values by forward fill and backward fill
#df_features = df_features.ffill().bfill()

from sklearn.model_selection import train_test_split

try:
  df_final_cohort.drop(df_final_cohort.index, inplace= True)
except:
  print('df_final_cohort does not exists')

#extracting patient ids for shock and non-shock group that has less than 20 % mmissing data 
# from sepsis onset till sepsis onset + 31 hours or from sepsis onset time till shock onset time

df_cohort_temp = df_icutime[(df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_timeoverlap_exists']==1)& (df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_percentNonMissingData']>=80) ]
print(df_cohort_temp.shape[0])

"""
df_shock = df_sepsisOnset_SepsisOnsetPlus31h_csvdata[df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'].notna()]
print(df_shock.shape[0])
print(df_shock.columns )
"""

df_cohort_temp['sepsis_onsettime'] =  pd.to_datetime(df_cohort_temp['sepsis_onsettime'])
df_cohort_temp['sepstic_shock_onsettime'] =  pd.to_datetime(df_cohort_temp['sepstic_shock_onsettime'])


# for non-shock
df_non_shock =  df_cohort_temp[df_cohort_temp['sepstic_shock_onsettime'].isna()]
print(df_non_shock.shape)

#for shock 
df_shock =  df_cohort_temp[df_cohort_temp['sepstic_shock_onsettime'].notna()]
print(df_shock.shape)

#for patients that got shock after sepsis onset + 1hour
df_shock_post1hourAfterSepsisOnset = df_shock[(df_shock['sepstic_shock_onsettime'] >= ( df_shock['sepsis_onsettime'] + datetime.timedelta(hours=1) )) ]
print(df_shock_post1hourAfterSepsisOnset.shape)

df_final_cohort = pd.DataFrame(columns=df_cohort_temp.columns )
df_final_cohort =  df_final_cohort.append(df_non_shock); # including all non-shock patients
df_final_cohort =  df_final_cohort.append(df_shock_post1hourAfterSepsisOnset); # including only shock patients who got shock after sepsis onset + 1 hour


print(df_final_cohort.columns)
#print(df_final_cohort)

df_final_cohort = df_final_cohort[df_final_cohort['subject_id']!= 52875]

#x = x.apply(pd.to_numeric)

df_final_cohort['has_shock'] = np.where(df_final_cohort['sepstic_shock_onsettime'].isna(), 0 , 1 )

x = df_final_cohort[['icustay_id', 'subject_id','sepsis_onsettime', 'sepstic_shock_onsettime']]

y = df_final_cohort['has_shock']

#print(x)
#print(y)
x_train_subjects, x_test_subjects, y_train_class, y_test_class = train_test_split(x, y, test_size=0.3,random_state=42)

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print('x_Train_Class: ', x_train_class)
y_train_class = df_features_train_subjects['HAS_SHOCK']
print('y_train_class: ', y_train_class)

# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']

pd.set_option('display.max_rows', 10)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)
pd.set_option('max_colwidth', 800)
print(x_train_reg[x_train_reg.isnull().any(axis=1)])

#fitting a GLM Regression model to predict sofa score:

from sklearn.model_selection import KFold
from xgboost import XGBRegressor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix, classification_report
#print(x_train_reg.shape)

#print(x_train_reg[x_train_reg.isnull().any(axis=1)].shape)

x_train_reg = x_train_reg.apply(pd.to_numeric)
x_train_reg = np.asarray(x_train_reg)

y_train_reg = y_train_reg.apply(pd.to_numeric)
y_train_reg = np.asarray(y_train_reg)


glm = sm.GLM(y_train_reg, x_train_reg, families= sm.families.Poisson() )
glm_Reg_model= glm.fit() 
print(glm_Reg_model.summary())

############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_test = df_features_test_subjects['HAS_SHOCK']


# x and y for classification
x_test_class = x_test[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

#print('x_test_class:' , x_test_class)

y_test_class = df_features_test_subjects['HAS_SHOCK']
#print('y_test_class:' , y_test_class)
#print(x_test_class[x_test_class.isnull().any(axis=1)])

# x and y for regression using x and y for classification

x_test_reg = x_test_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print(x_test_reg[x_test_reg.isnull().any(axis=1)])

y_test_reg = x_test_class['SOFA_SCORE']
print(y_test_reg)


x_test_reg = x_test_reg.apply(pd.to_numeric)
x_test_reg = np.asarray(x_test_reg)

y_test_reg = y_test_reg.apply(pd.to_numeric)
y_test_reg = np.asarray(y_test_reg)

import sklearn

rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'RMSE','R2','RSS']

class_columns = ['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]
  print(cur_index_regression_result)


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = glm_Reg_model.predict(x_test_reg_patient_id)
  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)



"""

x_test['SOFA_SCORE'] = reg_predictions
x_test_class['SOFA_SCORE'] = reg_predictions
#x_test['SOFA_SCORE'] = reg_predictions
"""
"""
ROOT MEAN SQUARE ERROR :  1.9681198043487174
RSS =  7258.930687441294
R2 =  0.0434026150225868
"""
# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

#                            SUBJECT_ID      RMSE        R2         RSS
# best subject id : 65871 -- 65871        0.182828    0.808047    0.100278
# worst subject id : 83065 -- 83065       5.40683     -8.91287    87.7014


print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())

###
# Mean RMSE :  1.950785837036735
# Mean R2 :  -2.0866560915723094
# Mean RSS :  98.9053206455354
###

import plotly.graph_objects as go
fig = go.Figure()
df_regression_predictions_best_patient = df_features_classification_test_patient_id[df_features_classification_test_patient_id['SUBJECT_ID'] == 65871]

#df_regression_predictions_best_patient.PRED_SOFA_SCORE = df_regression_predictions_best_patient.PRED_SOFA_SCORE.round()

fig.add_trace(go.Scatter(x=df_regression_predictions_best_patient.index, y=df_regression_predictions_best_patient.iloc[:,10], name = df_regression_predictions_best_patient.iloc[:,10].name, line = dict(color = '#17BECF'), opacity = 0.8))
fig.add_trace(go.Scatter(x=df_regression_predictions_best_patient.index, y=df_regression_predictions_best_patient.iloc[:,51], name = df_regression_predictions_best_patient.iloc[:,51].name, line = dict(color = '#CF1717'), opacity = 0.8))

fig.update_layout(title_text='Best Patient (all features)')

fig.show()
#83065

import plotly.graph_objects as go
fig = go.Figure()
df_regression_predictions_worst_patient = df_features_classification_test_patient_id[df_features_classification_test_patient_id['SUBJECT_ID'] == 83065]

#df_regression_predictions_worst_patient.PRED_SOFA_SCORE = df_regression_predictions_worst_patient.PRED_SOFA_SCORE.round()

fig.add_trace(go.Scatter(x=df_regression_predictions_worst_patient.index, y=df_regression_predictions_worst_patient.iloc[:,10], name = df_regression_predictions_worst_patient.iloc[:,10].name, line = dict(color = '#17BECF'), opacity = 0.8))
fig.add_trace(go.Scatter(x=df_regression_predictions_worst_patient.index, y=df_regression_predictions_worst_patient.iloc[:,51], name = df_regression_predictions_worst_patient.iloc[:,51].name, line = dict(color = '#CF1717'), opacity = 0.8))

fig.update_layout(title_text='Worst Patient (all features)')

fig.show()

"""# **Experimenting for regression**

**REMOVING THE DIFF FEATURES**
"""

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print('x_Train_Class: ', x_train_class)

y_train_class = df_features_train_subjects['HAS_SHOCK']

print('y_train_class: ', y_train_class)

# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']




############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

#fitting a GLM Regression model to predict sofa score:

from sklearn.model_selection import KFold
from xgboost import XGBRegressor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix, classification_report
#print(x_train_reg.shape)

#print(x_train_reg[x_train_reg.isnull().any(axis=1)].shape)

print(x_train_reg.columns)

x_train_reg = x_train_reg.apply(pd.to_numeric)
x_train_reg = np.asarray(x_train_reg)

y_train_reg = y_train_reg.apply(pd.to_numeric)
y_train_reg = np.asarray(y_train_reg)


glm = sm.GLM(y_train_reg, x_train_reg, families= sm.families.Poisson() )
glm_Reg_model= glm.fit() 
print(glm_Reg_model.summary())

import sklearn

rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'RMSE','R2','RSS']

class_columns = ['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']
# 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]
  print(cur_index_regression_result)


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = glm_Reg_model.predict(x_test_reg_patient_id)
  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)




# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())


"""

below for all features: 


#                            SUBJECT_ID      RMSE        R2         RSS
# best subject id :         -- 65871        0.182828    0.808047    0.100278
# worst subject id :       -- 83065       5.40683     -8.91287    87.7014


# Mean RMSE :  1.950785837036735
# Mean R2 :  -2.0866560915723094
# Mean RSS :  98.9053206455354


""""


"""
below for all features exluding diff features:

#                            SUBJECT_ID      RMSE        R2         RSS
# best subject id :          -- 82055         0           1         0
# worst subject id :         -- 83065   5.40683      -8.91287      87.7014


Mean RMSE :  1.924435343641713
Mean R2 :  -2.0759065951632745
Mean RSS :  98.80920369947012

"""**CHECKING FEATURE IMPORTANCE BY PLOTTING CORRELATION OF ALL FEATURES EXCLUDING THE DIFF**"""

# example of correlation feature selection for numerical data
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression
from matplotlib import pyplot

x_feat_imp = df_features[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]

x_feat_imp = x_feat_imp.apply(pd.to_numeric)

y_feat_imp = df_features['SOFA_SCORE']
y_feat_imp = y_feat_imp.apply(pd.to_numeric)

fs = SelectKBest(score_func=f_regression, k='all')
fs.fit(x_feat_imp, y_feat_imp)


for i in range(len(fs.scores_)):
	print('Feature %d: %f' % (i, fs.scores_[i]))
 
# plot the scores
pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)
pyplot.show()

for i in range(len(fs.scores_)):
  if fs.scores_[i] >= 50:
	  print('Feature %d: %f' % (i, fs.scores_[i]))

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print('x_Train_Class: ', x_train_class)

y_train_class = df_features_train_subjects['HAS_SHOCK']

print('y_train_class: ', y_train_class)

# x and y for regression using x and y for classification

x_train_reg = x_train_class[['RESP' ,  'ABPSYS' , 'ABPDIAS', 'ABPMEAN', 'SPO2' , 'RESP_STD' , 'ABPSYS_STD' , 'HR_ENT' , 'ABPSYS_ENT' , 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'SPO2_MIN', 'RESP_MAX' , 'ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 'ABPDIAS_STD' , 'ABPMEAN_STD', 'SPO2_STD' , 'TEMP_ENT' , 'RESP_HR_CORR',
'ABPDIAS_ABPSYS_CORR', 
'ABPMEAN_ABPSYS_CORR',
'ABPMEAN_ABPDIAS_CORR', 'SPO2_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX']]

print('numbver of features : ' , x_train_reg.shape[1]) 
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']




############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

#fitting a GLM Regression model to predict sofa score:

from sklearn.model_selection import KFold
from xgboost import XGBRegressor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix, classification_report
#print(x_train_reg.shape)

#print(x_train_reg[x_train_reg.isnull().any(axis=1)].shape)

print(x_train_reg.columns)

x_train_reg = x_train_reg.apply(pd.to_numeric)
x_train_reg = np.asarray(x_train_reg)

y_train_reg = y_train_reg.apply(pd.to_numeric)
y_train_reg = np.asarray(y_train_reg)


glm = sm.GLM(y_train_reg, x_train_reg, families= sm.families.Poisson() )
glm_Reg_model= glm.fit() 
#print(glm_Reg_model.summary())

import sklearn

rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'RMSE','R2','RSS']

class_columns = ['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']
# 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]
  print(cur_index_regression_result)


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['RESP' ,  'ABPSYS' , 'ABPDIAS', 'ABPMEAN', 'SPO2' , 'RESP_STD' , 'ABPSYS_STD' , 'HR_ENT' , 'ABPSYS_ENT' , 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'SPO2_MIN', 'RESP_MAX' , 'ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 'ABPDIAS_STD' , 'ABPMEAN_STD', 'SPO2_STD' , 'TEMP_ENT' , 'RESP_HR_CORR',
'ABPDIAS_ABPSYS_CORR', 
'ABPMEAN_ABPSYS_CORR',
'ABPMEAN_ABPDIAS_CORR', 'SPO2_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX']]
  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = glm_Reg_model.predict(x_test_reg_patient_id)
  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)




# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())


"""

below for all features: 


#                            SUBJECT_ID      RMSE        R2         RSS
# best subject id :         -- 65871        0.182828    0.808047    0.100278
# worst subject id :       -- 83065       5.40683     -8.91287    87.7014


# Mean RMSE :  1.950785837036735
# Mean R2 :  -2.0866560915723094
# Mean RSS :  98.9053206455354


"""


"""
below for all features exluding diff features:

#                            SUBJECT_ID      RMSE        R2         RSS
# best subject id :          -- 82055         0           1         0
# worst subject id :         -- 83065   5.40683      -8.91287      87.7014


Mean RMSE :  1.924435343641713
Mean R2 :  -2.0759065951632745
Mean RSS :  98.80920369947012

"""

"""**Checking feature immportance by polotting mutual info gain technique**"""

# example of mutual infomration gain feature selection for numerical data
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression
from matplotlib import pyplot
from sklearn.feature_selection import f_regression, mutual_info_regression


x_feat_imp = df_features[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]


x_feat_imp = x_feat_imp.apply(pd.to_numeric)

y_feat_imp = df_features['SOFA_SCORE']
y_feat_imp = y_feat_imp.apply(pd.to_numeric)


"""
x_feat_train, x_feat_test, y_feat_train, y_feat_test = train_test_split(x_feat_imp, y_feat_imp, test_size=0.3,random_state=42)

def select_features(x_feat_train, y_feat_train, x_feat_test):
	# configure to select all features
	fs = SelectKBest(score_func=mutual_info_regression, k='all')
	# learn relationship from training data

	fs.fit(x_feat_train, y_feat_train)
	
	return x_feat_train, x_feat_test, fs


x_feat_train_fs, x_feat_test_fs, fs = select_features(x_feat_train, y_feat_train, x_feat_test)
# what are scores for the features

for i in range(len(fs.scores_)):
	print('Feature %d: %f' % (i, fs.scores_[i]))
# plot the scores
pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)
pyplot.show()
"""
fs = SelectKBest(score_func=mutual_info_regression, k='all')
fs.fit(x_feat_imp, y_feat_imp)
for i in range(len(fs.scores_)):
	print('Feature %d: %f' % (i, fs.scores_[i]))
# plot the scores
pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)
pyplot.show()


for i in range(len(fs.scores_)):
  if fs.scores_[i] >= 0.025:
	  print('Feature %d: %f' % (i, fs.scores_[i]))

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print('x_Train_Class: ', x_train_class)

y_train_class = df_features_train_subjects['HAS_SHOCK']

print('y_train_class: ', y_train_class)

# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2',
'TEMP', 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD','HR_ENT','RESP_ENT',
'ABPSYS_ENT','ABPDIAS_ENT','ABPMEAN_ENT','TEMP_ENT','ABPDIAS_HR_CORR','ABPDIAS_ABPSYS_CORR','ABPMEAN_ABPSYS_CORR',
'ABPMEAN_ABPDIAS_CORR','HR_MIN','RESP_MIN','SPO2_MIN','ABPSYS_MIN','ABPDIAS_MIN','ABPMEAN_MIN','HR_MAX',
'SPO2_MAX','TEMP_MAX','ABPSYS_MAX','ABPDIAS_MAX','ABPMEAN_MAX']]

print('numbver of features : ' , x_train_reg.shape[1]) 
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']




############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']]
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

#fitting a GLM Regression model to predict sofa score:

from sklearn.model_selection import KFold
from xgboost import XGBRegressor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix, classification_report
#print(x_train_reg.shape)

#print(x_train_reg[x_train_reg.isnull().any(axis=1)].shape)

print(x_train_reg.columns)

x_train_reg = x_train_reg.apply(pd.to_numeric)
x_train_reg = np.asarray(x_train_reg)

y_train_reg = y_train_reg.apply(pd.to_numeric)
y_train_reg = np.asarray(y_train_reg)


glm = sm.GLM(y_train_reg, x_train_reg, families= sm.families.Poisson() )
glm_Reg_model= glm.fit() 
#print(glm_Reg_model.summary())

import sklearn

rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'RMSE','R2','RSS']

class_columns = ['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']
# 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2',
'TEMP', 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD','HR_ENT','RESP_ENT',
'ABPSYS_ENT','ABPDIAS_ENT','ABPMEAN_ENT','TEMP_ENT','ABPDIAS_HR_CORR','ABPDIAS_ABPSYS_CORR','ABPMEAN_ABPSYS_CORR',
'ABPMEAN_ABPDIAS_CORR','HR_MIN','RESP_MIN','SPO2_MIN','ABPSYS_MIN','ABPDIAS_MIN','ABPMEAN_MIN','HR_MAX',
'SPO2_MAX','TEMP_MAX','ABPSYS_MAX','ABPDIAS_MAX','ABPMEAN_MAX']]

  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = glm_Reg_model.predict(x_test_reg_patient_id)
  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)




# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())

"""**FEATURE IMPORTANCE WITH XGBOOST (all features)**"""

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]


y_train_class = df_features_train_subjects['HAS_SHOCK']


# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

print('numbver of features : ' , x_train_reg.shape[1]) 
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']




############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

from xgboost import XGBRegressor
model = XGBRegressor()
xgb_reg_model = model.fit(x_train_reg,y_train_reg)

import sklearn

rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'RMSE','R2','RSS']

class_columns = ['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX']
# 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


  #select_X_test = selection.transform(x_test_reg_patient_id)
  #reg_predictions = selection_model.predict(select_X_test)
  reg_predictions = xgb_reg_model.predict(x_test_reg_patient_id)

  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)




# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

#eval

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())

"""**feature importance using xgboost (selecting top features)**"""

from sklearn.datasets import make_regression
from xgboost import XGBRegressor
from matplotlib import pyplot


x = df_features[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y = df_features['SOFA_SCORE']

# define dataset
# define the model
model = XGBRegressor()
# fit the model
model.fit(x, y)
# get importance
importance = model.feature_importances_
# summarize feature importance
"""
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
"""
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()



for i,v in enumerate(importance):
  if v >= 0.015:
	  print('Feature: %0d, Score: %.5f' % (i,v))

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


for i in [41589 , 52875,  81849]:
    subject_ids_train = np.delete(subject_ids_train,np.where(subject_ids_train==i))



# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','HAS_SHOCK','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]


y_train_class = df_features_train_subjects['HAS_SHOCK']


# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

print('numbver of features : ' , x_train_reg.shape[1]) 
 #'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']




############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))



for i in [41589 , 52875,  81849]:
    subject_ids_test = np.delete(subject_ids_test,np.where(subject_ids_test==i))

# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','HAS_SHOCK','HOURS_BETWEEN','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

print(x_test[x_test['SUBJECT_ID']==82055 ])

# select features using threshold
from sklearn.feature_selection import SelectFromModel

selection = SelectFromModel(model, threshold=0.015, prefit=True)
print(selection)
select_X_train = selection.transform(x_train_reg)
print(select_X_train.shape)
# train model
selection_model = XGBRegressor()
selection_model.fit(select_X_train, y_train_reg)
"""
# eval model
select_X_test = selection.transform(X_test)
y_pred = selection_model.predict(select_X_test)
"""



import sklearn
from sklearn.metrics import mean_squared_error


rmse_list = [];
r2_list = [];
rss_list = [];

regression_result_cols = ['SUBJECT_ID', 'HOURS_BETWEEN','RMSE','R2','RSS',]

class_columns = ['SUBJECT_ID','HAS_SHOCK','HOURS_BETWEEN','TIME','RESP', 'ABPMEAN', 'SPO2', 'HR_STD' , 
                 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 
                 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'TEMP_ENT', 'RESP_HR_CORR', 'ABPMEAN_ABPDIAS_CORR', 'RESP_MIN', 'SPO2_MIN',
                  'TEMP_MIN',  'ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 'SPO2_MAX' , 'TEMP_MAX', 'ABPMEAN_MAX']
# 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF','PRED_SOFA_SCORE']

 

try:
  df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True)
  df_features_classification_test_patient_id.drop(df_features_classification_test_patient_id.index, inplace = True)
except:
  print('df_regression_result_indv_patients.drop(df_regression_result_indv_patients.index, inplace = True) does nnot exist')


df_regression_result_indv_patients = pd.DataFrame(columns= regression_result_cols)
df_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)
df_temp_features_classification_test_patient_id = pd.DataFrame(columns= class_columns)

for i in subject_ids_test:

  #print('subject :' , i);
  try:
    x_test_reg_patient_id.drop(x_test_reg_patient_id.index, inplace= True)
    
  except:
    print('x_test_reg_patient_id does not exist')


  cur_index_regression_result = df_regression_result_indv_patients.shape[0]


  features_test_patient_id = x_test[x_test['SUBJECT_ID'] == i]
  if i == 82055:
    print(features_test_patient_id)
  hours_between = features_test_patient_id.HOURS_BETWEEN.unique()

  df_temp_features_classification_test_patient_id = df_temp_features_classification_test_patient_id.append(features_test_patient_id); 
  


  x_test_reg_patient_id =  features_test_patient_id[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]


  select_X_test = selection.transform(x_test_reg_patient_id)
  reg_predictions = selection_model.predict(select_X_test)

  y_test_reg_patient_id = features_test_patient_id['SOFA_SCORE']


  reg_predictions = reg_predictions.round()

  #print('printing predictions')
  #print(reg_predictions)

  rms = np.sqrt(mean_squared_error(y_test_reg_patient_id, reg_predictions))
  #print('ROOT MEAN SQUARE ERROR : ',rms )
  
  rss = ((y_test_reg_patient_id - reg_predictions)**2).sum()

  #print("RSS = ", ((y_test_reg_patient_id - reg_predictions)**2).sum())
  #print("R2 = ", glm_regression_model.rsquared)
  R2 = sklearn.metrics.r2_score(y_test_reg_patient_id,reg_predictions)
  #print(R2)
  """
  SS_Residual = sum((y_test_reg_patient_id - reg_predictions)**2)       
  SS_Total = sum((y_test_reg_patient_id-np.mean(y_test_reg_patient_id))**2)     
  r_squared = 1 - (float(SS_Residual))/SS_Total
  print("R2 = ", r_squared)
  """

  df_regression_result_indv_patients.loc[cur_index_regression_result,'SUBJECT_ID'] = i;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'HOURS_BETWEEN'] = hours_between;
 
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RMSE'] = rms;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'R2'] = R2 ;
  df_regression_result_indv_patients.loc[cur_index_regression_result,'RSS'] = rss ;

  df_temp_features_classification_test_patient_id['PRED_SOFA_SCORE'] = reg_predictions

  df_features_classification_test_patient_id = df_features_classification_test_patient_id.append(df_temp_features_classification_test_patient_id)
  df_temp_features_classification_test_patient_id.drop(df_temp_features_classification_test_patient_id.index, inplace = True)




# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
#even with experiments, do the same as above

print(df_regression_result_indv_patients.sort_values("RMSE"))

print(df_features_classification_test_patient_id.shape)
print(df_features_classification_test_patient_id.columns)

print('Mean RMSE : ', df_regression_result_indv_patients.RMSE.mean())
print('Mean R2 : ', df_regression_result_indv_patients.R2.mean())
print('Mean RSS : ', df_regression_result_indv_patients.RSS.mean())

# also have one more additional column for number of hours between sepsis and shock

##### plots for the best and worst 
# AFTER ALL THE EXPERIMENTS WITH XGBOOST AND GLM, WE REALIZED THAT XGBOOST WITH TOP 24 FEATURES PERFORMS THE BEST:


import plotly.graph_objects as go
fig = go.Figure()
df_regression_predictions_best_patient = df_features_classification_test_patient_id[df_features_classification_test_patient_id['SUBJECT_ID'] == 82055]

#df_regression_predictions_best_patient.PRED_SOFA_SCORE = df_regression_predictions_best_patient.PRED_SOFA_SCORE.round()

fig.add_trace(go.Scatter(x=df_regression_predictions_best_patient.index, y=df_regression_predictions_best_patient.iloc[:,32], name = df_regression_predictions_best_patient.iloc[:,32].name, line = dict(color = '#17BECF'), opacity = 0.8))
fig.add_trace(go.Scatter(x=df_regression_predictions_best_patient.index, y=df_regression_predictions_best_patient.iloc[:,52], name = df_regression_predictions_best_patient.iloc[:,52].name, line = dict(color = '#CF1717'), opacity = 0.8))

fig.update_layout(title_text='Best Patient_XGBoost_top24Features')

fig.show()
#83065

import plotly.graph_objects as go
fig = go.Figure()
df_regression_predictions_worst_patient = df_features_classification_test_patient_id[df_features_classification_test_patient_id['SUBJECT_ID'] == 44319]

#df_regression_predictions_worst_patient.PRED_SOFA_SCORE = df_regression_predictions_worst_patient.PRED_SOFA_SCORE.round()

fig.add_trace(go.Scatter(x=df_regression_predictions_worst_patient.index, y=df_regression_predictions_worst_patient.iloc[:,32], name = df_regression_predictions_worst_patient.iloc[:,32].name, line = dict(color = '#17BECF'), opacity = 0.8))
fig.add_trace(go.Scatter(x=df_regression_predictions_worst_patient.index, y=df_regression_predictions_worst_patient.iloc[:,52], name = df_regression_predictions_worst_patient.iloc[:,52].name, line = dict(color = '#CF1717'), opacity = 0.8))

fig.update_layout(title_text='Worst Patient_XGBoost_top24Features')

fig.show()

"""# **CLASSIFICATION**"""

# building a GLM BIONOMIAL MODEL FOR CLASSIFICATION AND TRAINING IT WITH THE TRAIN DATA
x_train_class =  x_train_class[['RESP', 'ABPMEAN', 'SPO2', 'HR_STD' , 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 
                                'ABPDIAS_ENT', 'ABPMEAN_ENT', 'TEMP_ENT', 'RESP_HR_CORR', 'ABPMEAN_ABPDIAS_CORR', 'RESP_MIN', 'SPO2_MIN',
'TEMP_MIN',  'ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 'SPO2_MAX' , 'TEMP_MAX', 'ABPMEAN_MAX']]

x_train_class = x_train_class.apply(pd.to_numeric)
x_train_class = np.asarray(x_train_class)


y_train_class  = np.asarray(y_train_class)
y_train_class = y_train_class.astype(int)


glm_bionomial = sm.GLM(y_train_class, x_train_class, family=sm.families.Binomial())
glm_bio_model = glm_bionomial.fit()

import sklearn

print(df_features_classification_test_patient_id.columns)

df_features_classification_test_patient_id['SOFA_SCORE'] = df_features_classification_test_patient_id['PRED_SOFA_SCORE']

try:
  df_classification_result_indv_patients.drop(df_classification_result_indv_patients.index, inplace= True)

except:
  print('df_classification_result_indv_patients does not exists')


classification_result_cols = ['SUBJECT_ID', 'ACCURACY','PRECISION','RECALL','FSCORE']

df_classification_result_indv_patients = pd.DataFrame(columns= classification_result_cols)

for i in subject_ids_test:
  print(i)
  cur_index_classification_result = df_classification_result_indv_patients.shape[0]

  #print('subject :' , i);
  try:
    x_test_class_patient_id.drop(x_test_class_patient_id.index, inplace= True)
  except:
    print('x_test_class_patient_id does not exist')
  
  
  class_features_test_patient_id = df_features_classification_test_patient_id[df_features_classification_test_patient_id['SUBJECT_ID'] == i]

  print('aaaaaaaaa' , class_features_test_patient_id.shape)

  x_test_class_patient_id =  class_features_test_patient_id[['RESP', 'ABPMEAN', 'SPO2', 'HR_STD' , 
'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'TEMP_ENT', 'RESP_HR_CORR', 'ABPMEAN_ABPDIAS_CORR', 'RESP_MIN', 'SPO2_MIN',
'TEMP_MIN',  'ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 'SPO2_MAX' , 'TEMP_MAX', 'ABPMEAN_MAX']]


  y_test_class_patient_id = class_features_test_patient_id['HAS_SHOCK']


  x_test_class_patient_id = x_test_class_patient_id.apply(pd.to_numeric)
  x_test_class_patient_id = np.asarray(x_test_class_patient_id)
  
  
  y_test_class_patient_id = np.asarray(y_test_class_patient_id)
  y_test_class_patient_id = y_test_class_patient_id.astype(int)

  pred_probabilities_subject_id = glm_bio_model.predict(x_test_class_patient_id)

  print(len(y_test_class_patient_id))
  print(pred_probabilities_subject_id)
  fpr ='';
  tpr = '';
  thresholds = '';

  fpr, tpr, thresholds = metrics.roc_curve(y_test_class_patient_id, pred_probabilities_subject_id)

  gmeans = sqrt(tpr * (1-fpr))
  igx = argmax(gmeans) # thresholds[ix] --> best threshold
  print('best probabiloity for this patient : ', thresholds[igx])

  y_pred_class_patient_id = [ 0 if x < thresholds[ix]  else 1 for x in pred_probabilities_subject_id] 

  df_classification_result_indv_patients.loc[cur_index_classification_result,'SUBJECT_ID'] = i
  df_classification_result_indv_patients.loc[cur_index_classification_result,'ACCURACY'] = sklearn.metrics.accuracy_score(y_test_class_patient_id, y_pred_class_patient_id)
  df_classification_result_indv_patients.loc[cur_index_classification_result,'PRECISION'] = sklearn.metrics.precision_score(y_test_class_patient_id, y_pred_class_patient_id)
  df_classification_result_indv_patients.loc[cur_index_classification_result,'RECALL'] = sklearn.metrics.recall_score(y_test_class_patient_id, y_pred_class_patient_id)
  df_classification_result_indv_patients.loc[cur_index_classification_result,'FSCORE'] = sklearn.metrics.f1_score(y_test_class_patient_id, y_pred_class_patient_id)

  print(y_test_class_patient_id)
  print(y_pred_class_patient_id)

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

print(df_classification_result_indv_patients.sort_values("ACCURACY"))



print('Mean ACCURACY : ', df_classification_result_indv_patients.ACCURACY.mean())
print('Mean PRECISION : ', df_classification_result_indv_patients.PRECISION.mean())
print('Mean RECALL : ', df_classification_result_indv_patients.RECALL.mean())
print('Mean FSCORE : ', df_classification_result_indv_patients.FSCORE.mean())

##################. SUBJECT_ID  ACCURACY   PRECISION     RECALL     FSCORE
# best subject id : 65871 --    0.244238   0.657437      0.178957
# worst subject id : 99229 --     0         0             0         0