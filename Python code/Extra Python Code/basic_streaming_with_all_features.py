# -*- coding: utf-8 -*-
"""BASIC_streaming_WITH_ALL_FEATURES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZWV_4m_PO1xVjVTsTqq7d3DIsZzdR918
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import pandas as pd
import io
import pandas as pd
from IPython.display import display
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import os
import shutil
import posixpath
import urllib.request
import datetime
from collections import namedtuple

pd.set_option('display.max_rows', 50000)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)
pd.set_option('max_colwidth', 800)

drive.mount('/content/gdrive')

# Download All Time series data for 404 patients.

df_all256_withTemp = pd.read_csv('/content/gdrive/My Drive/Master thesis/df_ts_records_all256SepsisPatients(lessThan20%Missing)_fromSepsisOnset_ShockOnset_or_sepsisOnsetPlus31h_WITH_TEMP_SOFA.csv')
df_all256_withTemp['TIME'] =  pd.to_datetime(df_all256_withTemp['TIME'])
print(df_all256_withTemp.shape)
print(df_all256_withTemp.columns)

#cleaning data :  removing all negative values

df_all256_withTemp.HR = df_all256_withTemp.HR.mask(df_all256_withTemp.HR < 0)

df_all256_withTemp.RESP = df_all256_withTemp.RESP.mask(df_all256_withTemp.RESP < 0)

df_all256_withTemp.ABPSYS = df_all256_withTemp.ABPSYS.mask(df_all256_withTemp.ABPSYS < 0)

df_all256_withTemp.ABPDIAS = df_all256_withTemp.ABPDIAS.mask(df_all256_withTemp.ABPDIAS < 0)

df_all256_withTemp.ABPMEAN = df_all256_withTemp.ABPMEAN.mask(df_all256_withTemp.ABPMEAN < 0)

df_all256_withTemp.SPO2 = df_all256_withTemp.SPO2.mask(df_all256_withTemp.SPO2 < 0)

df_all256_withTemp.TEMP = df_all256_withTemp.TEMP.mask(df_all256_withTemp.TEMP < 0)


df_all256_withTemp.SOFA_SCORE = df_all256_withTemp.SOFA_SCORE.mask(df_all256_withTemp.SOFA_SCORE < 0)


df_all256_withTemp.RESP_SOFA = df_all256_withTemp.RESP_SOFA.mask(df_all256_withTemp.RESP_SOFA < 0)


df_all256_withTemp.LIVER_SOFA = df_all256_withTemp.LIVER_SOFA.mask(df_all256_withTemp.LIVER_SOFA < 0)


df_all256_withTemp.RENAL_SOFA = df_all256_withTemp.RENAL_SOFA.mask(df_all256_withTemp.RENAL_SOFA < 0)


df_all256_withTemp.CARDIO_SOFA = df_all256_withTemp.CARDIO_SOFA.mask(df_all256_withTemp.CARDIO_SOFA < 0)


df_all256_withTemp.CNS_SOFA = df_all256_withTemp.CNS_SOFA.mask(df_all256_withTemp.CNS_SOFA < 0)


df_all256_withTemp.COAG_SOFA = df_all256_withTemp.COAG_SOFA.mask(df_all256_withTemp.COAG_SOFA < 0)

# Missing value imputation by carry forward scheme
df_all256_withTemp_cleaned_MVimputed = df_all256_withTemp.ffill().bfill()

df_all256_withTemp_cleaned_MVimputed.HR = df_all256_withTemp_cleaned_MVimputed.HR.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.RESP = df_all256_withTemp_cleaned_MVimputed.RESP.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPSYS = df_all256_withTemp_cleaned_MVimputed.ABPSYS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPDIAS = df_all256_withTemp_cleaned_MVimputed.ABPDIAS.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.ABPMEAN = df_all256_withTemp_cleaned_MVimputed.ABPMEAN.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.SPO2 = df_all256_withTemp_cleaned_MVimputed.SPO2.round(decimals=4)
df_all256_withTemp_cleaned_MVimputed.TEMP = df_all256_withTemp_cleaned_MVimputed.TEMP.round(decimals=4)


df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE = df_all256_withTemp_cleaned_MVimputed.SOFA_SCORE.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA = df_all256_withTemp_cleaned_MVimputed.RENAL_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA = df_all256_withTemp_cleaned_MVimputed.LIVER_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.COAG_SOFA = df_all256_withTemp_cleaned_MVimputed.COAG_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA = df_all256_withTemp_cleaned_MVimputed.CARDIO_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.CNS_SOFA = df_all256_withTemp_cleaned_MVimputed.CNS_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed.RESP_SOFA = df_all256_withTemp_cleaned_MVimputed.RESP_SOFA.round(decimals=4)

df_all256_withTemp_cleaned_MVimputed['TIME'] =  pd.to_datetime(df_all256_withTemp_cleaned_MVimputed['TIME'])

print(df_all256_withTemp_cleaned_MVimputed[df_all256_withTemp_cleaned_MVimputed.isnull().any(axis=1)])

subject_ids = df_all256_withTemp_cleaned_MVimputed.SUBJECT_ID.unique()
print(len(subject_ids))

for i in [41589 , 52875,  81849]:
    subject_ids = np.delete(subject_ids,np.where(subject_ids==i))

print(subject_ids)

from google.colab import files
uploaded = files.upload()

df_icutime = pd.read_csv(io.BytesIO(uploaded['Only_AllSepsisPatients_with_MissingData_FromSepsisOnset_ToShockOnset_or_SepsisOnset+31h.csv']))
print (df_icutime.columns)
#df_icutime = df_icutime[['subject_id','icustay_id','intime','outtime','sepsis_onsettime']]
#print (df_icutime.columns)
"""
df_icutime['intime'] =  pd.to_datetime(df_icutime['intime'])
df_icutime['outtime'] =  pd.to_datetime(df_icutime['outtime'])
"""

import seaborn as sns
data_corr = df_all256_withTemp_cleaned_MVimputed[['HR', 'SPO2', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'RESP', 'TEMP','SOFA_SCORE']]
corr = data_corr.corr()# calculating the correlation between the above vital signs
sns.heatmap(corr, square=True) # plotting the correlation

import scipy
import collections
from scipy.stats import entropy

feature_cols= ['TIME','ICUSTAY_ID','SUBJECT_ID','SEPSIS_ONSETTIME','SEPSIS_SHOCK_ONSETTIME','HAS_SHOCK',
               'HR',
               'RESP',
               'ABPSYS',
               'ABPDIAS',
               'ABPMEAN',
               'SPO2',
               'TEMP' ,
               'SOFA_SCORE',

               'HR_STD',
               'RESP_STD',
               'ABPSYS_STD',
               'ABPDIAS_STD',
               'ABPMEAN_STD',
               'SPO2_STD',
               'TEMP_STD',
               'SOFA_SCORE_STD',
               
               'HR_ENT',
               'RESP_ENT',
               'ABPSYS_ENT',
               'ABPDIAS_ENT',
               'ABPMEAN_ENT',
               'SPO2_ENT',
               'TEMP_ENT',
               'SOFA_SCORE_ENT',

               'ABPDIAS_HR_CORR',
               'RESP_HR_CORR',
               'ABPDIAS_ABPSYS_CORR',
               'ABPMEAN_ABPSYS_CORR',
               'ABPMEAN_ABPDIAS_CORR',

                'HR_MIN',
                'RESP_MIN',
                'SPO2_MIN',
                'TEMP_MIN',
                'SOFA_SCORE_MIN',
                'ABPSYS_MIN',
                'ABPDIAS_MIN',
                'ABPMEAN_MIN',
                'HR_MAX',
                'RESP_MAX',
                'SPO2_MAX',
                'TEMP_MAX',
                'SOFA_SCORE_MAX',
                'ABPSYS_MAX',
                'ABPDIAS_MAX',
                'ABPMEAN_MAX',

               'HR_DIFF',
               'RESP_DIFF',
               'ABPSYS_DIFF',
               'ABPDIAS_DIFF',
               'ABPMEAN_DIFF',
               'SPO2_DIFF',
               'TEMP_DIFF' ,
               'SOFA_SCORE_DIFF'
               ] 
              



temp_feature_cols= ['TIME',
               'HR',
               'RESP',
               'ABPSYS',
               'ABPDIAS',
               'ABPMEAN',
               'SPO2',
               'TEMP',
               'SOFA_SCORE'
               ] 


try:
  df_features.drop(df_features.index, inplace=True)
except:
  print('df_features does not exists')

df_features  =  pd.DataFrame(columns=feature_cols);

for subject_id in subject_ids:
  curr_idx = df_features.shape[0]
  

  icustay_id = df_icutime.loc[df_icutime.subject_id==subject_id , 'icustay_id'].values[0]

  icu_intime = df_icutime.loc[df_icutime.subject_id==subject_id , 'intime'].values[0]
  sepsis_onsettime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepsis_onsettime'].values[0]

  shock_onsetttime = df_icutime.loc[df_icutime.subject_id==subject_id , 'sepstic_shock_onsettime'].values[0]

  if str(shock_onsetttime) == 'nan':
    
    has_shock = 0 ;
    #print('not a shock patient')
    df_tsdata_subjectid_entireTimeBeforeShock = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=31)) )  )]
    skip = 31
  else:
    has_shock = 1 ;

    datetime_shock_date = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S').date()
    datetime_shock_time_hour  = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S').time().hour
    df_tsdata_subjectid_entireTimeBeforeShock = df_all256_withTemp_cleaned_MVimputed[(df_all256_withTemp_cleaned_MVimputed['SUBJECT_ID'] == subject_id) & ( ( df_all256_withTemp_cleaned_MVimputed['TIME'] >= datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S')    ) & ( df_all256_withTemp_cleaned_MVimputed['TIME'] <= (datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S')) )  )]
    hours_between = datetime.datetime.strptime(shock_onsetttime,'%Y-%m-%d %H:%M:%S')  - datetime.datetime.strptime(sepsis_onsettime,'%Y-%m-%d %H:%M:%S') 
    duration_in_s = hours_between.total_seconds()
    q, r = divmod(duration_in_s, 3600)
    skip = int(q + int(bool(r)))

  
  
  first_row = df_tsdata_subjectid_entireTimeBeforeShock.iloc[0,:]
  
  base_min = int(first_row['TIME'].strftime('%M') )

  df_tsdata_subjectid_entireTimeBeforeShock = df_tsdata_subjectid_entireTimeBeforeShock[temp_feature_cols]
  df_features_temp =pd.DataFrame(columns=temp_feature_cols)
  
  """

  #for mean per hour
  df_features_temp = df_tsdata_subjectid_entireTimeBeforeShock.resample('60min',base=base_min,  on='TIME').mean()
  print('after aggregating mean : ', df_features_temp.shape[0])
  


  # for standard deviation
  df_features_temp_std = df_tsdata_subjectid_entireTimeBeforeShock.resample('60min',base=base_min,  on='TIME').std()

  df_features_temp_std =  df_features_temp_std[['HR','RESP','ABPSYS', 'ABPDIAS','ABPMEAN','SPO2','TEMP', 'SOFA_SCORE']]

  df_features_temp_std.columns = ['HR_STD','RESP_STD','ABPSYS_STD','ABPDIAS_STD','ABPMEAN_STD','SPO2_STD','TEMP_STD','SOFA_SCORE_STD']
  df_features_temp = pd.concat([df_features_temp, df_features_temp_std], axis=1)

  print('after aggregating mean annd std : ', df_features_temp.shape[0])
  print(df_features_temp)

  #print(' df_features_temp after concatenation with std')
  # for calculation of entropy
  """
  #q, r = divmod(df_tsdata_subjectid_entireTimeBeforeShock.shape[0], 60)
  #skip = q + int(bool(r)) # rounds to next greater integer (always ceiling)
  #print(skip)
  """
  skip = df_features_temp.shape[0]
  #print('printing skip : ', skip)

  start_window_idx = 0
  end_window_idx = 60
  """
  #For mean calculation
  hr_mean_list = []
  resp_mean_list = []
  spo2_mean_list = []
  temp_mean_list = []
  sofa_mean_list = []
  abpsys_mean_list = []
  abpdias_mean_list = []
  abpmean_mean_list = []

  hr_mean = '';
  resp_mean = '';
  spo2_mean = '';
  temp_mean = '';
  sofa_mean = '';
  abpsys_mean = '';
  abpdias_mean = '';
  abpmean_mean = '';

  # for std calculation
  hr_std_list = []
  resp_std_list = []
  spo2_std_list = []
  temp_std_list = []
  sofa_std_list = []
  abpsys_std_list = []
  abpdias_std_list = []
  abpmean_std_list = []

  hr_std = '';
  resp_std = '';
  spo2_std = '';
  temp_std = '';
  sofa_std = '';
  abpsys_std = '';
  abpdias_std = '';
  abpmean_std = '';


  #for entropy calculation
  hr_entropy_list=[]
  resp_entropy_list = []
  spo2_entropy_list = []
  temp_entropy_list = []
  sofa_entropy_list = []
  abpsys_entropy_list = []
  abpdias_entropy_list = []
  abpmean_entropy_list = []

  hr_entropy = '';
  resp_entropy = '';
  spo2_entropy = '';
  temp_entropy = '';
  sofa_entropy = '';
  abpsys_entropy = '';
  abpdias_entropy = '';
  abpmean_entropy = '';

  # for correlation calculation
  abpdias_hr_corr_list = [];
  resp_hr_corr_list = [];
  abpdias_abpsys_corr_list = [];
  abpmean_abpsys_corr_list = [];
  abpmean_abpdias_corr_list = [];


  # for min calculation
  hr_min_list=[]
  resp_min_list = []
  spo2_min_list = []
  temp_min_list = []
  sofa_min_list = []
  abpsys_min_list = []
  abpdias_min_list = []
  abpmean_min_list = []

  hr_min = '';
  resp_min = '';
  spo2_min = '';
  temp_min = '';
  sofa_min = '';
  abpsys_min = '';
  abpdias_min = '';
  abpmean_min = '';

  # for max calculation
  hr_max_list=[]
  resp_max_list = []
  spo2_max_list = []
  temp_max_list = []
  sofa_max_list = []
  abpsys_max_list = []
  abpdias_max_list = []
  abpmean_max_list = []

  hr_max = '';
  resp_max = '';
  spo2_max = '';
  temp_max = '';
  sofa_max = '';
  abpsys_max = '';
  abpdias_max = '';
  abpmean_max = '';

  #for time
  time_list = [];
  has_shock_list = [] ;

  init_time = first_row['TIME']
  end_time = first_row['TIME'] + datetime.timedelta(minutes =60)


  for i in range(skip):
    
    #print('start_window_time : ', init_time)
    #print('end_window_time : ', end_time)

    #df_subset = df_tsdata_subjectid_entireTimeBeforeShock.iloc[start_window_idx:end_window_idx,:]
    df_subset = df_tsdata_subjectid_entireTimeBeforeShock[(df_tsdata_subjectid_entireTimeBeforeShock['TIME'] >= init_time) & (df_tsdata_subjectid_entireTimeBeforeShock['TIME'] < end_time) ]
  
    if ( has_shock == 1 ) & (init_time.date() == datetime_shock_date)  & ( init_time.time().hour >= datetime_shock_time_hour) :
      time_has_shock = 1
    else:
      time_has_shock = 0
    
    has_shock_list.append(time_has_shock)

    
    hr_mean = '';
    resp_mean = '';
    spo2_mean = '';
    temp_mean = '';
    sofa_mean = '';
    abpsys_mean = '';
    abpdias_mean = '';
    abpmean_mean = '';


    hr_std = '';
    resp_std = '';
    spo2_std = '';
    temp_std = '';
    sofa_std = '';
    abpsys_std = '';
    abpdias_std = '';
    abpmean_std = '';


    hr_entropy = '';
    resp_entropy = '';
    spo2_entropy = '';
    temp_entropy = '';
    sofa_entropy = '';
    abpsys_entropy = '';
    abpdias_entropy = '';
    abpmean_entropy = '';

    abpdias_hr_corr = '';
    resp_hr_corr= '';
    abpdias_abpsys_corr= '';
    abpmean_abpsys_corr= '';
    abpmean_abpdias_corr= '';


    hr_min = '';
    resp_min = '';
    spo2_min = '';
    temp_min = '';
    sofa_min = '';
    abpsys_min = '';
    abpdias_min = '';
    abpmean_min = '';


    hr_max = '';
    resp_max = '';
    spo2_max = '';
    temp_max = '';
    sofa_max = '';
    abpsys_max = '';
    abpdias_max = '';
    abpmean_max = '';


    #extracting series for all vitals + sofa
    hr_series = df_subset.HR
    resp_series = df_subset.RESP
    spo2_series = df_subset.SPO2
    sofa_series =df_subset.SOFA_SCORE
    temp_series = df_subset.TEMP
    abpsys_series = df_subset.ABPSYS
    abpdias_series = df_subset.ABPDIAS
    abpmean_series = df_subset.ABPMEAN

    # other way to calculate the entropy
    #hr_entropy = sample_entropy(hr_series) # from tsfresh package
    #hr_entropy_list.append(hr_entropy)

    
    hr_data = hr_series.value_counts()           # counts occurrence of each value
    hr_entropy = scipy.stats.entropy(hr_data)  # get entropy from counts
    hr_entropy_list.append(hr_entropy) 
    hr_min = hr_series.min()
    hr_min_list.append(hr_min)
    hr_max = hr_series.max()
    hr_max_list.append(hr_max)
    ##### for mean and std
    hr_mean = hr_series.mean()
    hr_mean_list.append(hr_mean)
    hr_std = hr_series.std()
    hr_std_list.append(hr_std)





    resp_data = resp_series.value_counts()           # counts occurrence of each value
    resp_entropy = scipy.stats.entropy(resp_data)  # get entropy from counts
    resp_entropy_list.append(resp_entropy)
    resp_min = resp_series.min()
    resp_min_list.append(resp_min)
    resp_max = resp_series.max()
    resp_max_list.append(resp_max)
    ### for mmean and std
    resp_mean = resp_series.mean()
    resp_mean_list.append(resp_mean)
    resp_std = resp_series.std()
    resp_std_list.append(resp_std)


    spo2_data = spo2_series.value_counts()           # counts occurrence of each value
    spo2_entropy = scipy.stats.entropy(spo2_data)  # get entropy from counts
    spo2_entropy_list.append(spo2_entropy)
    spo2_min = spo2_series.min()
    spo2_min_list.append(spo2_min)
    spo2_max = spo2_series.max()
    spo2_max_list.append(spo2_max)
    ### for mmean and std
    spo2_mean = spo2_series.mean()
    spo2_mean_list.append(spo2_mean)
    spo2_std = spo2_series.std()
    spo2_std_list.append(spo2_std)


    temp_data = temp_series.value_counts()           # counts occurrence of each value
    temp_entropy = scipy.stats.entropy(temp_data)  # get entropy from counts
    temp_entropy_list.append(temp_entropy)
    temp_min = temp_series.min()
    temp_min_list.append(temp_min)
    temp_max = temp_series.max()
    temp_max_list.append(temp_max)
    ### for mmean and std
    temp_mean = temp_series.mean()
    temp_mean_list.append(temp_mean)
    temp_std = temp_series.std()
    temp_std_list.append(temp_std)


    sofa_data = sofa_series.value_counts()           # counts occurrence of each value
    sofa_entropy = scipy.stats.entropy(sofa_data)  # get entropy from counts
    sofa_entropy_list.append(sofa_entropy)
    sofa_min = sofa_series.min()
    sofa_min_list.append(sofa_min)
    sofa_max = sofa_series.max()
    sofa_max_list.append(sofa_max)
    ### for mmean and std
    sofa_mean = sofa_series.mean()
    sofa_mean_list.append(sofa_mean)
    sofa_std = sofa_series.std()
    sofa_std_list.append(sofa_std)

    abpsys_data = abpsys_series.value_counts()           # counts occurrence of each value
    abpsys_entropy = scipy.stats.entropy(abpsys_data)  # get entropy from counts
    abpsys_entropy_list.append(abpsys_entropy)
    abpsys_min = abpsys_series.min()
    abpsys_min_list.append(abpsys_min)
    abpsys_max = abpsys_series.max()
    abpsys_max_list.append(abpsys_max)
    ### for mmean and std
    abpsys_mean = abpsys_series.mean()
    abpsys_mean_list.append(abpsys_mean)
    abpsys_std = abpsys_series.std()
    abpsys_std_list.append(abpsys_std)


    abpdias_data = abpdias_series.value_counts()           # counts occurrence of each value
    abpdias_entropy = scipy.stats.entropy(abpdias_data)  # get entropy from counts
    abpdias_entropy_list.append(abpdias_entropy)
    abpdias_min = abpdias_series.min()
    abpdias_min_list.append(abpdias_min)
    abpdias_max = abpdias_series.max()
    abpdias_max_list.append(abpdias_max)
    ### for mmean and std
    abpdias_mean = abpdias_series.mean()
    abpdias_mean_list.append(abpdias_mean)
    abpdias_std = abpdias_series.std()
    abpdias_std_list.append(abpdias_std)


    abpmean_data = abpmean_series.value_counts()           # counts occurrence of each value
    abpmean_entropy = scipy.stats.entropy(abpmean_data)  # get entropy from counts
    abpmean_entropy_list.append(abpmean_entropy)
    abpmean_min = abpmean_series.min()
    abpmean_min_list.append(abpmean_min)
    abpmean_max = abpmean_series.max()
    abpmean_max_list.append(abpmean_max)
    ### for mmean and std
    abpmean_mean = abpmean_series.mean()
    abpmean_mean_list.append(abpmean_mean)
    abpmean_std = abpmean_series.std()
    abpmean_std_list.append(abpmean_std)

    


    abpdias_hr_corr = abpdias_series.corr(hr_series) 
    abpdias_hr_corr_list.append(abpdias_hr_corr);
    
    resp_hr_corr = resp_series.corr(hr_series) 
    resp_hr_corr_list.append(resp_hr_corr);
    

    abpdias_abpsys_corr = abpdias_series.corr(abpsys_series) 
    abpdias_abpsys_corr_list.append(abpdias_abpsys_corr);
    
    abpmean_abpsys_corr = abpmean_series.corr(abpsys_series) 
    abpmean_abpsys_corr_list.append(abpmean_abpsys_corr);
    

    abpmean_abpdias_corr = abpmean_series.corr(abpdias_series) 
    abpmean_abpdias_corr_list.append(abpmean_abpdias_corr);
   
    time_list.append(init_time)

    init_time = end_time # incrementing times for the next window
    end_time = init_time + datetime.timedelta(minutes=60)

    #start_window_idx = end_window_idx 
    #end_window_idx = end_window_idx + 60
    

  #['HR_STD','RESP_STD','ABPSYS_STD','ABPDIAS_STD','ABPMEAN_STD','SPO2_STD','TEMP_STD','SOFA_SCORE_STD']
  #print('df_features_temp lenght: ', df_features_temp.shape)
  #print('hr entrpy list lenght : ', len(hr_entropy_list))

  #for mean and std
  df_features_temp['HR'] = hr_mean_list
  df_features_temp['RESP'] = resp_mean_list
  df_features_temp['ABPSYS'] = abpsys_mean_list
  df_features_temp['ABPDIAS'] = abpdias_mean_list
  df_features_temp['ABPMEAN'] = abpmean_mean_list
  df_features_temp['SPO2'] = spo2_mean_list
  df_features_temp['TEMP'] = temp_mean_list
  df_features_temp['SOFA_SCORE'] = sofa_mean_list

  df_features_temp['HR_STD'] = hr_std_list
  df_features_temp['RESP_STD'] = resp_std_list
  df_features_temp['ABPSYS_STD'] = abpsys_std_list
  df_features_temp['ABPDIAS_STD'] = abpdias_std_list
  df_features_temp['ABPMEAN_STD'] = abpmean_std_list
  df_features_temp['SPO2_STD'] = spo2_std_list
  df_features_temp['TEMP_STD'] = temp_std_list
  df_features_temp['SOFA_SCORE_STD'] = sofa_std_list

  df_features_temp['TIME'] = time_list
  df_features_temp['HR_ENT'] = hr_entropy_list
  df_features_temp['RESP_ENT'] = resp_entropy_list
  df_features_temp['ABPSYS_ENT'] = abpsys_entropy_list
  df_features_temp['ABPDIAS_ENT'] = abpdias_entropy_list
  df_features_temp['ABPMEAN_ENT'] = abpmean_entropy_list
  df_features_temp['SPO2_ENT'] = spo2_entropy_list
  df_features_temp['TEMP_ENT'] = temp_entropy_list
  df_features_temp['SOFA_SCORE_ENT'] = sofa_entropy_list


  df_features_temp['ABPDIAS_HR_CORR'] = abpdias_hr_corr_list
  df_features_temp['RESP_HR_CORR'] = resp_hr_corr_list
  df_features_temp['ABPDIAS_ABPSYS_CORR'] = abpdias_abpsys_corr_list
  df_features_temp['ABPMEAN_ABPSYS_CORR'] = abpmean_abpsys_corr_list
  df_features_temp['ABPMEAN_ABPDIAS_CORR'] = abpmean_abpdias_corr_list
  

  #min 

  df_features_temp['HR_MIN'] = hr_min_list
  df_features_temp['RESP_MIN'] = resp_min_list 
  df_features_temp['SPO2_MIN'] = spo2_min_list 
  df_features_temp['TEMP_MIN'] = temp_min_list 
  df_features_temp['SOFA_SCORE_MIN'] = sofa_min_list 
  df_features_temp['ABPSYS_MIN'] = abpsys_min_list
  df_features_temp['ABPDIAS_MIN'] = abpdias_min_list 
  df_features_temp['ABPMEAN_MIN'] = abpmean_min_list

  #MAX
  df_features_temp['HR_MAX'] = hr_max_list
  df_features_temp['RESP_MAX'] = resp_max_list 
  df_features_temp['SPO2_MAX'] = spo2_max_list 
  df_features_temp['TEMP_MAX'] = temp_max_list 
  df_features_temp['SOFA_SCORE_MAX'] = sofa_max_list 
  df_features_temp['ABPSYS_MAX'] = abpsys_max_list
  df_features_temp['ABPDIAS_MAX'] = abpdias_max_list 
  df_features_temp['ABPMEAN_MAX'] = abpmean_max_list

  
  
  df_features_temp['HR_DIFF']=df_features_temp['HR'] -df_features_temp['HR'].shift(1)
  df_features_temp['RESP_DIFF']=df_features_temp['RESP'] -df_features_temp['RESP'].shift(1)
  df_features_temp['ABPSYS_DIFF']=df_features_temp['ABPSYS'] -df_features_temp['ABPSYS'].shift(1)
  df_features_temp['ABPDIAS_DIFF']=df_features_temp['ABPDIAS'] -df_features_temp['ABPDIAS'].shift(1)
  df_features_temp['ABPMEAN_DIFF']=df_features_temp['ABPMEAN'] -df_features_temp['ABPMEAN'].shift(1)
  df_features_temp['SPO2_DIFF']=df_features_temp['SPO2'] -df_features_temp['SPO2'].shift(1)
  df_features_temp['TEMP_DIFF']=df_features_temp['TEMP'] -df_features_temp['TEMP'].shift(1)
  df_features_temp['SOFA_SCORE_DIFF']=df_features_temp['SOFA_SCORE'] -df_features_temp['SOFA_SCORE'].shift(1)

  #df_features_temp['HAS_SHOCK'] = has_shock_list


  df_features_temp['ICUSTAY_ID'] = icustay_id
  df_features_temp['SUBJECT_ID'] = subject_id
  df_features_temp['SEPSIS_ONSETTIME'] = sepsis_onsettime
  df_features_temp['SEPSIS_SHOCK_ONSETTIME'] = shock_onsetttime
  df_features_temp['HAS_SHOCK'] = has_shock
  
  
  
  # forward and backward fill the correlation columns
  corr_cols = ['ABPDIAS_HR_CORR', 'RESP_HR_CORR','ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR','ABPMEAN_ABPDIAS_CORR']

  df_features_temp.loc[:,corr_cols] = df_features_temp.loc[:,corr_cols].ffill().bfill()


  

  
  

  icu_intime='';
  sepsis_onsettime='';
  shock_onsetttime = '';
  has_shock ='';
  base_min = '';
  

  
  df_features = df_features.append(df_features_temp);
  df_tsdata_subjectid_entireTimeBeforeShock.drop(df_tsdata_subjectid_entireTimeBeforeShock.index, inplace = True)
  df_features_temp.drop(df_features_temp.index, inplace=True)

print(df_features.columns)
print(df_features.shape)

print(df_features[df_features['SUBJECT_ID']== 69272])

#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])

df_test = df_features[['SUBJECT_ID','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX' ]]

print(df_test[df_test.isnull().any(axis=1)])

#elimninate the nan values by forward fill and backward fill
#df_features = df_features.ffill().bfill()

from sklearn.model_selection import train_test_split

try:
  df_final_cohort.drop(df_final_cohort.index, inplace= True)
except:
  print('df_final_cohort does not exists')

#extracting patient ids for shock and non-shock group that has less than 20 % mmissing data 
# from sepsis onset till sepsis onset + 31 hours or from sepsis onset time till shock onset time

df_cohort_temp = df_icutime[(df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_timeoverlap_exists']==1)& (df_icutime['Sepsis_SepsisOnset+ShockOnsetOR31h_percentNonMissingData']>=80) ]
print(df_cohort_temp.shape[0])

"""
df_shock = df_sepsisOnset_SepsisOnsetPlus31h_csvdata[df_sepsisOnset_SepsisOnsetPlus31h_csvdata['sepstic_shock_onsettime'].notna()]
print(df_shock.shape[0])
print(df_shock.columns )
"""

df_cohort_temp['sepsis_onsettime'] =  pd.to_datetime(df_cohort_temp['sepsis_onsettime'])
df_cohort_temp['sepstic_shock_onsettime'] =  pd.to_datetime(df_cohort_temp['sepstic_shock_onsettime'])


# for non-shock
df_non_shock =  df_cohort_temp[df_cohort_temp['sepstic_shock_onsettime'].isna()]
print(df_non_shock.shape)

#for shock 
df_shock =  df_cohort_temp[df_cohort_temp['sepstic_shock_onsettime'].notna()]
print(df_shock.shape)

#for patients that got shock after sepsis onset + 1hour
df_shock_post1hourAfterSepsisOnset = df_shock[(df_shock['sepstic_shock_onsettime'] >= ( df_shock['sepsis_onsettime'] + datetime.timedelta(hours=1) )) ]
print(df_shock_post1hourAfterSepsisOnset.shape)

df_final_cohort = pd.DataFrame(columns=df_cohort_temp.columns )
df_final_cohort =  df_final_cohort.append(df_non_shock); # including all non-shock patients
df_final_cohort =  df_final_cohort.append(df_shock_post1hourAfterSepsisOnset); # including only shock patients who got shock after sepsis onset + 1 hour


print(df_final_cohort.columns)
#print(df_final_cohort)

df_final_cohort = df_final_cohort[df_final_cohort['subject_id']!= 52875]

#x = x.apply(pd.to_numeric)

df_final_cohort['has_shock'] = np.where(df_final_cohort['sepstic_shock_onsettime'].isna(), 0 , 1 )

x = df_final_cohort[['icustay_id', 'subject_id','sepsis_onsettime', 'sepstic_shock_onsettime']]

y = df_final_cohort['has_shock']

#print(x)
#print(y)
x_train_subjects, x_test_subjects, y_train_class, y_test_class = train_test_split(x, y, test_size=0.3,random_state=42)

############### preparing features for train  (classification and regression). ######################

subject_ids_train = x_train_subjects.subject_id.unique()
print(len(subject_ids_train))


# taking subset of features only for the train subject ids

df_features_train_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_train)]

df_features_train_subjects = df_features_train_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])
#print(df_features_train_subjects[df_features_train_subjects.isnull().any(axis=1)])


x_train = df_features_train_subjects[['SUBJECT_ID','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train = df_features_train_subjects['HAS_SHOCK']

# x and y for classification
x_train_class = x_train[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print('x_Train_Class: ', x_train_class)
y_train_class = df_features_train_subjects['HAS_SHOCK']
print('y_train_class: ', y_train_class)

# x and y for regression using x and y for classification

x_train_reg = x_train_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_train_reg = x_train_class['SOFA_SCORE']

pd.set_option('display.max_rows', 10)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)
pd.set_option('max_colwidth', 800)
print(x_train_reg[x_train_reg.isnull().any(axis=1)])

#fitting a GLM Regression model to predict sofa score:

from sklearn.model_selection import KFold
from xgboost import XGBRegressor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix, classification_report
#print(x_train_reg.shape)

#print(x_train_reg[x_train_reg.isnull().any(axis=1)].shape)

x_train_reg = x_train_reg.apply(pd.to_numeric)
x_train_reg = np.asarray(x_train_reg)

y_train_reg = y_train_reg.apply(pd.to_numeric)
y_train_reg = np.asarray(y_train_reg)


glm = sm.GLM(y_train_reg, x_train_reg, families= sm.families.Poisson() )
glm_Reg_model= glm.fit()

############### preparing features for test  (classification and regression). ######################

subject_ids_test = x_test_subjects.subject_id.unique()
print(len(subject_ids_test))


# taking subset of features only for the train subject ids

df_features_test_subjects = df_features[df_features.SUBJECT_ID.isin(subject_ids_test)]

df_features_test_subjects = df_features_test_subjects.dropna(subset=['HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF'])


x_test = df_features_test_subjects[['SUBJECT_ID','TIME','HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

y_test = df_features_test_subjects['HAS_SHOCK']


# x and y for classification
x_test_class = x_test[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

#print('x_test_class:' , x_test_class)

y_test_class = df_features_test_subjects['HAS_SHOCK']
#print('y_test_class:' , y_test_class)
#print(x_test_class[x_test_class.isnull().any(axis=1)])

# x and y for regression using x and y for classification

x_test_reg = x_test_class[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP',
 'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
 'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
 'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
 'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
 'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
 'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF' ]]

print(x_test_reg[x_test_reg.isnull().any(axis=1)])

y_test_reg = x_test_class['SOFA_SCORE']
print(y_test_reg)


x_test_reg = x_test_reg.apply(pd.to_numeric)
x_test_reg = np.asarray(x_test_reg)

y_test_reg = y_test_reg.apply(pd.to_numeric)
y_test_reg = np.asarray(y_test_reg)

import sklearn


reg_predictions = glm_Reg_model.predict(x_test_reg)

print('printing predictions')
print(reg_predictions)


rms = np.sqrt(mean_squared_error(y_test_reg, reg_predictions))
print('ROOT MEAN SQUARE ERROR : ',rms )



print("RSS = ", ((y_test_reg - reg_predictions)**2).sum())
#print("R2 = ", glm_regression_model.rsquared)
#R2 = sklearn.metrics.r2_score(y_test_reg,reg_predictions)
#print(R2)
SS_Residual = sum((y_test_reg - reg_predictions)**2)       
SS_Total = sum((y_test_reg-np.mean(y_test_reg))**2)     
r_squared = 1 - (float(SS_Residual))/SS_Total
print("R2 = ", r_squared)

x_test['SOFA_SCORE'] = reg_predictions
x_test_class['SOFA_SCORE'] = reg_predictions
#x_test['SOFA_SCORE'] = reg_predictions

"""
ROOT MEAN SQUARE ERROR :  1.9681198043487174
RSS =  7258.930687441294
R2 =  0.0434026150225868
"""
# plot the actual sofa and predicted sofa
# do regression for every patient and check RMSE for each patient - look for best patient and worst patient.
even with experiments, do the same as above

# building a GLM BIONOMIAL MODEL FOR CLASSIFICATION AND TRAINING IT WITH THE TRAIN DATA
x_train_class = x_train_class.apply(pd.to_numeric)
x_train_class = np.asarray(x_train_class)


y_train_class  = np.asarray(y_train_class)
y_train_class = y_train_class.astype(int)


glm_bionomial = sm.GLM(y_train_class, x_train_class, family=sm.families.Binomial())
glm_bio_model = glm_bionomial.fit()

# to know an optimal threshold

from sklearn import metrics
from matplotlib import pyplot
from numpy import sqrt
from numpy import argmax
from sklearn.metrics import precision_recall_curve


x_test_class = np.asarray(x_test_class)
y_test_class = np.asarray(y_test_class)

y_test_class = y_test_class.astype(int)


pred_prob = glm_bio_model.predict(x_test_class)
print(len(pred_prob))
print(len(y_test_class))

#######3
fpr, tpr, thresholds = metrics.roc_curve(y_test_class, pred_prob)
pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')
pyplot.plot(fpr, tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
pyplot.legend()
# show the plot
pyplot.show()
gmeans = sqrt(tpr * (1-fpr))
ix = argmax(gmeans)
print('Best Threshold according to the G-Mean=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))

########## calculating best threshold according to the best F1-score:

precision, recall, thresholds = precision_recall_curve(y_test_class, pred_prob)
# convert to f score
fscore = (2 * precision * recall) / (precision + recall)
# locate the index of the largest f score
ix = argmax(fscore)
print('Best Threshold according to the F-Score=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))


########## calculating best threshold according to the  Youden’s J statistic.:
fpr, tpr, thresholds = metrics.roc_curve(y_test_class, pred_prob)
J = tpr - fpr
ix = argmax(J)
best_thresh = thresholds[ix]
print('Best Threshold according to the Youden’s J statistic=%f' % (best_thresh))

# Testing classification using 1 hour sliding window

print(subject_ids_test) # 79184
#print(df_features_test_subjects[df_features_test_subjects['SUBJECT_ID']==79184 ]) 

try:
  df_predictions.drop(df_predictions.index, inplace=True)
except:
  print('df_predictions does not exist')

df_predictions = pd.DataFrame(columns=['SUBJECT_ID', 'PREDICTED_TIME', 'PREDICTED_CLASS', 'ACTUAL_CLASS', 'SHOCK_ONSETTIME'])

for patient in subject_ids_test: 
  curr_idx = df_predictions.shape[0]

  icustay_id = df_icutime.loc[df_icutime.subject_id==patient , 'icustay_id'].values[0]

  icu_intime = df_icutime.loc[df_icutime.subject_id==patient , 'intime'].values[0]
  sepsis_onsettime = df_icutime.loc[df_icutime.subject_id==patient , 'sepsis_onsettime'].values[0]

  shock_onsetttime = df_icutime.loc[df_icutime.subject_id==patient , 'sepstic_shock_onsettime'].values[0]

  x_test_subject_id = x_test[(x_test['SUBJECT_ID'] == patient) ] # extracting features for this test subject id
  

  
  if str(shock_onsetttime) == 'nan':
    has_shock = 0 ;    
  else:
    has_shock = 1 ;
  

  
  skip = int(x_test_subject_id.shape[0])
  print('looping for number of times : ', skip)


  for i in range(skip) : 
    x_test_subject_id_hourly_feature = x_test_subject_id.iloc[i,:]

    x_test_subject_id_hourly_feature_input = x_test_subject_id_hourly_feature[['HR', 'RESP', 'ABPSYS', 'ABPDIAS', 'ABPMEAN', 'SPO2', 'TEMP','SOFA_SCORE',
                                                    'HR_STD', 'RESP_STD', 'ABPSYS_STD', 'ABPDIAS_STD', 'ABPMEAN_STD', 'SPO2_STD', 'TEMP_STD', 
                                                    'HR_ENT', 'RESP_ENT', 'ABPSYS_ENT', 'ABPDIAS_ENT', 'ABPMEAN_ENT', 'SPO2_ENT', 'TEMP_ENT',  
                                                    'ABPDIAS_HR_CORR', 'RESP_HR_CORR', 'ABPDIAS_ABPSYS_CORR', 'ABPMEAN_ABPSYS_CORR', 'ABPMEAN_ABPDIAS_CORR', 
                                                    'HR_MIN', 'RESP_MIN', 'SPO2_MIN', 'TEMP_MIN','ABPSYS_MIN', 'ABPDIAS_MIN', 'ABPMEAN_MIN', 
                                                    'HR_MAX', 'RESP_MAX', 'SPO2_MAX', 'TEMP_MAX', 'ABPSYS_MAX', 'ABPDIAS_MAX', 'ABPMEAN_MAX',
                                                    'HR_DIFF', 'RESP_DIFF',  'ABPSYS_DIFF', 'ABPDIAS_DIFF', 'ABPMEAN_DIFF', 'SPO2_DIFF', 'TEMP_DIFF']]

    #####has_shock_hourly_feature = x_test_subject_id_hourly_feature['HAS_SHOCK'] ######

    x_test_subject_id_hourly_feature_input = x_test_subject_id_hourly_feature_input.apply(pd.to_numeric)

    x_test_subject_id_hourly_feature_input = np.asarray(x_test_subject_id_hourly_feature_input)


    pred_probability_subject_id_hourly_feature = glm_bio_model.predict(x_test_subject_id_hourly_feature_input)

    print(pred_probability_subject_id_hourly_feature)

    if pred_probability_subject_id_hourly_feature >= 0.463986:
      pred_class_subject_id =  1
      current_row = x_test_subject_id.iloc[i,:]
      pred_time = current_row['TIME']
      break;
    else:
      pred_class_subject_id = 0
      current_row = x_test_subject_id.iloc[i,:]
      pred_time = current_row['TIME']

  df_predictions.loc[curr_idx,'SUBJECT_ID'] = patient
  df_predictions.loc[curr_idx,'PREDICTED_TIME'] = pred_time
  df_predictions.loc[curr_idx,'PREDICTED_CLASS'] = pred_class_subject_id
  df_predictions.loc[curr_idx,'ACTUAL_CLASS']  = has_shock # has_shock_hourly_feature
  df_predictions.loc[curr_idx,'SHOCK_ONSETTIME'] = shock_onsetttime

predicted_class = df_predictions.PREDICTED_CLASS
predicted_class = np.asarray(predicted_class)
predicted_class = predicted_class.astype(int)

actual_class = df_predictions.ACTUAL_CLASS
actual_class = np.asarray(actual_class)
actual_class = actual_class.astype(int)





from sklearn import metrics
print('Accuracy: ', metrics.accuracy_score(actual_class, predicted_class))
print('Precision: ', metrics.precision_score(actual_class, predicted_class))
print('Recall: ', metrics.recall_score(actual_class, predicted_class))
print('F1 score: ', metrics.f1_score(actual_class, predicted_class))

df_correct_predictitons = df_predictions[(df_predictions['PREDICTED_CLASS'] == 1 ) & (df_predictions['ACTUAL_CLASS'] == 1 )]
df_correct_predictitons['SHOCK_ONSETTIME'] =  pd.to_datetime(df_correct_predictitons['SHOCK_ONSETTIME'])
df_correct_predictitons['PREDICTED_TIME'] =  pd.to_datetime(df_correct_predictitons['PREDICTED_TIME'])
df_correct_predictitons['TIME_DIFF_ONSET_PRED'] = (df_correct_predictitons['SHOCK_ONSETTIME'] - df_correct_predictitons['PREDICTED_TIME']).astype('timedelta64[h]')

import pandas as pd
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
print(df_correct_predictitons)


"""
Accuracy:  0.40789473684210525
Precision:  0.39436619718309857
Recall:  0.9333333333333333
F1 score:  0.5544554455445544

"""

# classify every patient  and calculate the accuracy , precision ,,,........

# plots as well for the best and worst

